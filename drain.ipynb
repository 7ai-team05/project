{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781cfb05",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3130287328.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mPREDICTION_KEY =\u001b[39m\n                     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import io\n",
    "\n",
    "PREDICTION_KEY = \n",
    "ENDPOINT_URL = \n",
    "\n",
    "headers = {\n",
    "    \"Prediction-Key\" : PREDICTION_KEY,\n",
    "    \"Content-Type\" : \"application/octet-stream\"\n",
    "}\n",
    "\n",
    "def predict_with_api(image: Image.Image):\n",
    "    buf = io.BytesIO()\n",
    "    image.save(buf, format='JPEG')\n",
    "    byte_data = buf.getvalue()\n",
    "\n",
    "    response = requests.post(ENDPOINT_URL, headers=headers, data=byte_data)\n",
    "\n",
    "    predictions = response.json()['predictions']\n",
    "\n",
    "    top_predictions = sorted(predictions, key=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39c763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* Running on public URL: https://25e5d76dbffe845179.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://25e5d76dbffe845179.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# 1) 내 정보로 아래 두 변수를 수정하세요.\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "PREDICTION_KEY = \"BBvYKDdr5RDpSMjG34Z2XXw3hLxzlAQkktCPXwHTLleSagQPHGg0JQQJ99BEACYeBjFXJ3w3AAAIACOGH9bC\"\n",
    "ENDPOINT_URL    = \"https://7aiteam05cv-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/2ae6121f-4235-4dce-bf2a-fbace9444880/classify/iterations/Iteration12/image\"\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "\n",
    "\n",
    "def predict_clean_heavy(img: Image.Image) -> dict:\n",
    "    \"\"\"\n",
    "    Gradio로 입력받은 PIL 이미지를 JPEG 바이트로 변환해\n",
    "    Custom Vision Prediction API에 POST 요청을 보냅니다.\n",
    "    반환되는 JSON 안의 'predictions' 필드에서\n",
    "    tagName(라벨)과 probability(확률)만 뽑아서\n",
    "    {'clean': 확률, 'heavy': 확률} 형태의 dict를 리턴합니다.\n",
    "    \"\"\"\n",
    "    # 1) PIL Image → JPEG 바이트 변환\n",
    "    with io.BytesIO() as buffer:\n",
    "        img.save(buffer, format=\"JPEG\")\n",
    "        image_bytes = buffer.getvalue()\n",
    "\n",
    "    # 2) 요청 헤더 구성\n",
    "    headers = {\n",
    "        \"Prediction-Key\": PREDICTION_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "\n",
    "    # 3) API 호출 (POST)\n",
    "    response = requests.post(\n",
    "        ENDPOINT_URL,\n",
    "        headers=headers,\n",
    "        data=image_bytes\n",
    "    )\n",
    "    response.raise_for_status()  # 오류 시 예외 발생\n",
    "\n",
    "    # 4) JSON 결과 파싱\n",
    "    result = response.json()\n",
    "    predictions = result.get(\"predictions\", [])\n",
    "\n",
    "    # 5) Gradio Label 컴포넌트에 맞게 {label:probability} dict 생성\n",
    "    output = {}\n",
    "    for pred in predictions:\n",
    "        name = pred.get(\"tagName\")\n",
    "        prob = pred.get(\"probability\", 0.0)\n",
    "        # Gradio Label에 주려면 0~1 사이의 확률 값을 그대로 넘기면 됩니다.\n",
    "        output[name] = prob\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    demo = gr.Interface(\n",
    "    fn=predict_clean_heavy,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=2, label=\"확률 (clean vs heavy)\"),\n",
    "    title=\"Custom Vision: Clean vs Heavy 분류\",\n",
    "    description=\"\"\"\n",
    "    웹캠으로 빗물받이 사진을 찍으면 Azure Custom Vision 이진 분류 모델에 보내서 \n",
    "    'clean'과 'heavy' 각각의 확률을 실시간으로 보여줍니다.\n",
    "    \"\"\",\n",
    "    allow_flagging=\"never\"\n",
    "    )\n",
    "\n",
    "    demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e43bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://b7f47bf0277f1421f5.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b7f47bf0277f1421f5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# 1) 내 정보로 아래 두 변수를 수정하세요.\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "PREDICTION_KEY = \"BBvYKDdr5RDpSMjG34Z2XXw3hLxzlAQkktCPXwHTLleSagQPHGg0JQQJ99BEACYeBjFXJ3w3AAAIACOGH9bC\"\n",
    "ENDPOINT_URL    = \"https://7aiteam05cv-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/2ae6121f-4235-4dce-bf2a-fbace9444880/classify/iterations/Iteration12/image\"\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "\n",
    "\n",
    "def predict_clean_heavy(img: Image.Image) -> tuple[dict, str]:\n",
    "    \"\"\"\n",
    "    Gradio로 입력받은 PIL 이미지를 JPEG 바이트로 변환해\n",
    "    Custom Vision Prediction API에 POST 요청을 보냅니다.\n",
    "    반환되는 JSON 안의 'predictions' 필드에서\n",
    "    tagName(라벨)과 probability(확률)을 소문자 키로 바꿔서\n",
    "    {'clean': 확률, 'heavy': 확률} 형태의 dict를 만들고,\n",
    "    그 중 'heavy' 확률이 70%, 90% 경계에 따라 다른 상태 메시지를 출력합니다.\n",
    "    \"\"\"\n",
    "    # 1) PIL Image → JPEG 바이트 변환\n",
    "    with io.BytesIO() as buffer:\n",
    "        img.save(buffer, format=\"JPEG\")\n",
    "        image_bytes = buffer.getvalue()\n",
    "\n",
    "    # 2) 요청 헤더 구성\n",
    "    headers = {\n",
    "        \"Prediction-Key\": PREDICTION_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "\n",
    "    # 3) API 호출 (POST)\n",
    "    response = requests.post(\n",
    "        ENDPOINT_URL,\n",
    "        headers=headers,\n",
    "        data=image_bytes\n",
    "    )\n",
    "    response.raise_for_status()  # 오류 시 예외 발생\n",
    "\n",
    "    # 4) JSON 결과 파싱\n",
    "    result = response.json()\n",
    "    predictions = result.get(\"predictions\", [])\n",
    "\n",
    "    # 5) 라벨을 모두 소문자로 바꿔서 { 'clean':확률, 'heavy':확률 } dict 생성\n",
    "    output = {}\n",
    "    for pred in predictions:\n",
    "        # 원래 tagName이 \"Heavy\" 혹은 \"Clean\" 처럼 첫 글자만 대문자라면,\n",
    "        # name_lower에 소문자 버전으로 저장하면 이후 비교가 훨씬 명확해집니다.\n",
    "        name = pred.get(\"tagName\", \"\")\n",
    "        name_lower = name.lower()  # 예: \"Heavy\" → \"heavy\"\n",
    "        prob = pred.get(\"probability\", 0.0)\n",
    "        output[name_lower] = prob\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    # 6) 'heavy' 확률을 올바르게 가져와서 상태 메시지 생성\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    heavy_prob = output.get(\"heavy\", 0.0)\n",
    "\n",
    "    if heavy_prob >= 0.9:\n",
    "        status_text = \"🚨 Heavy 수준: 확률 ≥ 90% (매우 막힘)\"\n",
    "    elif heavy_prob >= 0.7:\n",
    "        status_text = \"⚠️ Heavy 수준: 확률 ≥ 70% (중간/높음 막힘)\"\n",
    "    elif heavy_prob >= 0.6:\n",
    "        status_text = \"✅ Heavy 확률 ≥ 60% (크게 막힌 상태 아님)\"\n",
    "    else:\n",
    "        status_text = \"✅ Clean\"\n",
    "\n",
    "    # Gradio 함수는 (label_dict, status_text) 형태로 반환\n",
    "    return output, status_text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    demo = gr.Interface(\n",
    "        fn=predict_clean_heavy,\n",
    "        inputs=gr.Image(type=\"pil\"),\n",
    "        outputs=[\n",
    "            gr.Label(num_top_classes=2, label=\"확률 (clean vs heavy)\"),\n",
    "            gr.Text(label=\"Heavy 확률 상태\")\n",
    "        ],\n",
    "        title=\"Custom Vision: Clean vs Heavy 분류\",\n",
    "        description=\"\"\"\n",
    "        웹캠으로 빗물받이 사진을 찍으면 Azure Custom Vision 이진 분류 모델에 보내서 \n",
    "        'clean'과 'heavy' 각각의 확률을 실시간으로 보여줍니다.\n",
    "        그리고 heavy 확률이 70% 이상일 때와 90% 이상일 때\n",
    "        각각 다른 메시지를 아래에 표시해 줍니다.\n",
    "        \"\"\",\n",
    "        allow_flagging=\"never\"\n",
    "    )\n",
    "\n",
    "    demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb270b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://dd3dcc1d9ae3cdecf0.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://dd3dcc1d9ae3cdecf0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# 1) 아래 두 변수를 실제 값으로 수정하세요: (빗물받이 여부 판별 모델)\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "DETECTION_KEY = \"5sloqMYWiZSpfCd7HZgQ9ZpfuQAXnRWwjSw648WjXGr5Fy5f7imcJQQJ99BFACYeBjFXJ3w3AAAIACOGBDCR\"\n",
    "DETECTION_ENDPOINT_URL = \"https://7aiteam05ai012-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/f360eeb2-f8df-441e-8bed-f27d3ef1797a/detect/iterations/Iteration2/image\"\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# 2) 아래 두 변수를 실제 값으로 수정하세요: (오염도 분류 모델: Clean vs Heavy)\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "POLLUTION_KEY = \"BBvYKDdr5RDpSMjG34Z2XXw3hLxzlAQkktCPXwHTLleSagQPHGg0JQQJ99BEACYeBjFXJ3w3AAAIACOGH9bC\"\n",
    "POLLUTION_ENDPOINT_URL = \"https://7aiteam05cv-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/2ae6121f-4235-4dce-bf2a-fbace9444880/classify/iterations/Iteration12/image\"\n",
    "\n",
    "\n",
    "def predict_sequence(img: Image.Image) -> tuple[dict, dict, str]:\n",
    "    \"\"\"\n",
    "    1) Gradio로 입력받은 PIL 이미지를 JPEG 바이트로 변환\n",
    "    2) [빗물받이 여부 모델]에 POST 요청 -> 결과를 { 'drain':확률, 'not_drain':확률 }로 정리\n",
    "    3) 'drain' 확률이 'not_drain'보다 높으면(=빗물받이 판정):\n",
    "         -> [오염도 모델]에 POST 요청 -> 결과를 { 'clean':확률, 'heavy':확률 }로 정리\n",
    "       아니면(=빗물받이가 아니면) 두 번째 모델 호출 생략\n",
    "    4) 상태 메시지를 세 가지 경우로 분기하여 문자열로 생성\n",
    "       - 빗물받이가 아님\n",
    "       - 오염도(heavy) < 70%\n",
    "       - 오염도(heavy) ≥ 70% & < 90%\n",
    "       - 오염도(heavy) ≥ 90%\n",
    "    5) Gradio에 (detection_dict, pollution_dict, status_text) 튜플로 반환\n",
    "    \"\"\"\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    # A) PIL Image → JPEG 바이트 변환 (공통)\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    with io.BytesIO() as buffer:\n",
    "        img.save(buffer, format=\"JPEG\")\n",
    "        image_bytes = buffer.getvalue()\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    # B) 빗물받이 여부 모델 호출 (Detection)\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    headers_det = {\n",
    "        \"Prediction-Key\": DETECTION_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "    response_det = requests.post(\n",
    "        DETECTION_ENDPOINT_URL,\n",
    "        headers=headers_det,\n",
    "        data=image_bytes\n",
    "    )\n",
    "    response_det.raise_for_status()\n",
    "    result_det = response_det.json()\n",
    "    preds_det = result_det.get(\"predictions\", [])\n",
    "\n",
    "    # 출력 딕셔너리를 모두 소문자 키로 정리\n",
    "    detection_dict = {}\n",
    "    for pred in preds_det:\n",
    "        name = pred.get(\"tagName\", \"\")\n",
    "        prob = pred.get(\"probability\", 0.0)\n",
    "        detection_dict[name.lower()] = prob\n",
    "    # 예) detection_dict == { 'drain': 0.85, 'not_drain': 0.15 }\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    # C) 빗물받이 판정 기준: drain 확률 vs not_drain 확률\n",
    "    #    (여기서는 더 높은 쪽을 선택)\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    drain_prob = detection_dict.get(\"street_drain\", 0.0)\n",
    "    not_drain_prob = detection_dict.get(\"unstreet_drain\", 0.0)\n",
    "\n",
    "    # 기본값: 오염도 모델 호출을 건너뛸 때 사용\n",
    "    pollution_dict = { \"clean\": 0.0, \"heavy\": 0.0 }\n",
    "    status_text = \"\"\n",
    "\n",
    "    if drain_prob > not_drain_prob:\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        # D) 빗물받이(Drain)으로 판정되었으므로 오염도(클린/헤비) 모델 호출\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        headers_pol = {\n",
    "            \"Prediction-Key\": POLLUTION_KEY,\n",
    "            \"Content-Type\": \"application/octet-stream\"\n",
    "        }\n",
    "        response_pol = requests.post(\n",
    "            POLLUTION_ENDPOINT_URL,\n",
    "            headers=headers_pol,\n",
    "            data=image_bytes\n",
    "        )\n",
    "        response_pol.raise_for_status()\n",
    "        result_pol = response_pol.json()\n",
    "        preds_pol = result_pol.get(\"predictions\", [])\n",
    "\n",
    "        # clean/heavy 확률을 소문자 키로 정리\n",
    "        pollution_dict = {}\n",
    "        for pred in preds_pol:\n",
    "            name = pred.get(\"tagName\", \"\")\n",
    "            prob = pred.get(\"probability\", 0.0)\n",
    "            pollution_dict[name.lower()] = prob\n",
    "        # 예) pollution_dict == { 'clean': 0.10, 'heavy': 0.90 }\n",
    "\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        # E) pollution_dict['heavy'] 값에 따라 상태 메시지 분기\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        heavy_prob = pollution_dict.get(\"heavy\", 0.0)\n",
    "        if heavy_prob >= 0.9:\n",
    "            status_text = \"🚨 Heavy 수준: 확률 ≥ 90% (매우 막힘)\"\n",
    "        elif heavy_prob >= 0.7:\n",
    "            status_text = \"⚠️ Heavy 수준: 확률 ≥ 70% (중간/높음 막힘)\"\n",
    "        elif heavy_prob >= 0.6:\n",
    "            status_text = \"✅ Heavy 확률 ≥ 60% (크게 막힌 상태 아님)\"\n",
    "        else:\n",
    "            status_text = \"✅ Clean\"\n",
    "    else:\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        # F) 빗물받이가 아닐 때: pollution_dict는 0.0 기본값 사용, 메시지 설정\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        status_text = \"❌ 빗물받이가 아닙니다.\"\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    # G) Gradio로 반환: (빗물받이 판별 dict, 오염도 dict, 상태 메시지)\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    return detection_dict, pollution_dict, status_text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo = gr.Interface(\n",
    "        fn=predict_sequence,\n",
    "        inputs=gr.Image(type=\"pil\"),\n",
    "        outputs=[\n",
    "            gr.Label(label=\"빗물받이 여부 (Drain vs NotDrain)\"),\n",
    "            gr.Label(label=\"오염도 (Clean vs Heavy)\"),\n",
    "            gr.Text(label=\"상태 메시지\")\n",
    "        ],\n",
    "        title=\"Custom Vision: 빗물받이 여부 ➔ 오염도 순차 분류\",\n",
    "        description=\"\"\"\n",
    "        1. 먼저 업로드된 사진이 빗물받이인지 아닌지 Custom Vision 모델로 판정합니다.  \n",
    "        2. '빗물받이(drain)'로 판정되면, 두 번째 모델을 호출하여 'clean' vs 'heavy' 오염도를 예측합니다.  \n",
    "        3. 결과는 각각 확률과 상태 메시지로 보여줍니다.  \n",
    "        - 빗물받이가 아닌 경우: 상태 메시지에 '❌ 빗물받이가 아닙니다.' 출력  \n",
    "        - 빗물받이인 경우, heavy 확률에 따라 70%·90% 경계로 상태 메시지 분기  \n",
    "        \"\"\",\n",
    "        allow_flagging=\"never\"\n",
    "    )\n",
    "    demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
