{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c1b752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image, ImageDraw\n",
    "import requests, io\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from gradio_image_annotation import image_annotator\n",
    "\n",
    "# Custom Vision 설정\n",
    "PREDICTION_KEY = \"5k8oJDDDmqLn5Yy9n1Q16CHetW6H0pvTjFPj1Q4JpQl7dAVJE0WhJQQJ99BEACYeBjFXJ3w3AAAIACOGZmg4\"\n",
    "ENDPOINT_URL = \"https://cv7934-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/92adf90f-3b67-4923-b2eb-1804da244279/detect/iterations/Iteration1/image\"\n",
    "\n",
    "# 감지 함수\n",
    "def detect_with_boxes(image: Image.Image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    headers = {\n",
    "        \"Prediction-Key\": PREDICTION_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "    response = requests.post(ENDPOINT_URL, headers=headers, data=buffered.getvalue())\n",
    "    results = response.json()\n",
    "\n",
    "    # 결과 그리기\n",
    "    image_with_boxes = image.copy()\n",
    "    draw = ImageDraw.Draw(image_with_boxes)\n",
    "    for pred in results[\"predictions\"]:\n",
    "        if pred[\"probability\"] > 0.5:\n",
    "            w, h = image.width, image.height\n",
    "            box = pred[\"boundingBox\"]\n",
    "            left = box[\"left\"] * w\n",
    "            top = box[\"top\"] * h\n",
    "            right = left + box[\"width\"] * w\n",
    "            bottom = top + box[\"height\"] * h\n",
    "            draw.rectangle([left, top, right, bottom], outline=\"red\", width=2)\n",
    "            draw.text((left, top), f\"{pred['tagName']} ({pred['probability']:.2f})\", fill=\"red\")\n",
    "\n",
    "    return image_with_boxes\n",
    "\n",
    "# 업로드 → 결과 이미지 + 태깅용 원본 전달\n",
    "def handle_image_upload(image: Image.Image):\n",
    "    ai_result = detect_with_boxes(image)\n",
    "\n",
    "    # numpy 배열 전달\n",
    "    annotator_input = {\n",
    "        \"image\": np.array(image.convert(\"RGB\")),  # <== base64 ❌\n",
    "        \"annotations\": []\n",
    "    }\n",
    "\n",
    "    return ai_result, annotator_input\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🚬 담배꽁초 감지 (AI vs 사용자)\")\n",
    "\n",
    "    image_input = gr.Image(type=\"pil\", label=\"📤 이미지 업로드\")\n",
    "\n",
    "    with gr.Row():\n",
    "        ai_output = gr.Image(label=\"🤖 AI 감지 결과\")\n",
    "        annotator = image_annotator(\n",
    "            label_list=[\"사용자\"],\n",
    "            label_colors=[(0, 0, 255)],\n",
    "            scale=False\n",
    "        )\n",
    "\n",
    "    image_input.change(\n",
    "        fn=handle_image_upload,\n",
    "        inputs=image_input,\n",
    "        outputs=[ai_output, annotator]\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e1082",
   "metadata": {},
   "source": [
    "## 감지 후 태깅 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71d7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 저장 요청됨: <class 'dict'> {'image': array([[[ 5, 22, 18],\n",
      "        [ 5, 22, 18],\n",
      "        [ 6, 23, 19],\n",
      "        ...,\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15]],\n",
      "\n",
      "       [[ 5, 22, 18],\n",
      "        [ 5, 22, 18],\n",
      "        [ 6, 23, 19],\n",
      "        ...,\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15]],\n",
      "\n",
      "       [[ 5, 22, 18],\n",
      "        [ 5, 22, 18],\n",
      "        [ 6, 23, 19],\n",
      "        ...,\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 4, 41, 26],\n",
      "        [ 4, 41, 26],\n",
      "        [ 4, 41, 26],\n",
      "        ...,\n",
      "        [38, 64, 60],\n",
      "        [39, 65, 63],\n",
      "        [39, 65, 63]],\n",
      "\n",
      "       [[ 4, 41, 24],\n",
      "        [ 4, 41, 24],\n",
      "        [ 4, 41, 24],\n",
      "        ...,\n",
      "        [39, 65, 61],\n",
      "        [39, 65, 61],\n",
      "        [39, 65, 61]],\n",
      "\n",
      "       [[ 4, 41, 24],\n",
      "        [ 4, 41, 24],\n",
      "        [ 4, 41, 24],\n",
      "        ...,\n",
      "        [39, 66, 59],\n",
      "        [39, 65, 61],\n",
      "        [39, 65, 61]]], shape=(700, 700, 3), dtype=uint8), 'boxes': [{'label': '사용자', 'color': (0, 0, 255), 'xmin': 100, 'ymin': 79, 'xmax': 499, 'ymax': 479}, {'label': '사용자', 'color': (0, 0, 255), 'xmin': 147, 'ymin': 164, 'xmax': 577, 'ymax': 618}], 'orientation': 0}\n",
      "💾 저장 요청됨: <class 'dict'> {'image': array([[[ 5, 22, 18],\n",
      "        [ 5, 22, 18],\n",
      "        [ 6, 23, 19],\n",
      "        ...,\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15]],\n",
      "\n",
      "       [[ 5, 22, 18],\n",
      "        [ 5, 22, 18],\n",
      "        [ 6, 23, 19],\n",
      "        ...,\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15]],\n",
      "\n",
      "       [[ 5, 22, 18],\n",
      "        [ 5, 22, 18],\n",
      "        [ 6, 23, 19],\n",
      "        ...,\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15],\n",
      "        [ 5, 16, 15]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 4, 41, 26],\n",
      "        [ 4, 41, 26],\n",
      "        [ 4, 41, 26],\n",
      "        ...,\n",
      "        [38, 64, 60],\n",
      "        [39, 65, 63],\n",
      "        [39, 65, 63]],\n",
      "\n",
      "       [[ 4, 41, 24],\n",
      "        [ 4, 41, 24],\n",
      "        [ 4, 41, 24],\n",
      "        ...,\n",
      "        [39, 65, 61],\n",
      "        [39, 65, 61],\n",
      "        [39, 65, 61]],\n",
      "\n",
      "       [[ 4, 41, 24],\n",
      "        [ 4, 41, 24],\n",
      "        [ 4, 41, 24],\n",
      "        ...,\n",
      "        [39, 66, 59],\n",
      "        [39, 65, 61],\n",
      "        [39, 65, 61]]], shape=(700, 700, 3), dtype=uint8), 'boxes': [{'label': '사용자', 'color': (0, 0, 255), 'xmin': 147, 'ymin': 164, 'xmax': 577, 'ymax': 618}], 'orientation': 0}\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image, ImageDraw\n",
    "import requests, io, json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from gradio_image_annotation import image_annotator\n",
    "\n",
    "# ─────────────────────────────────────\n",
    "# Custom Vision 설정\n",
    "# ─────────────────────────────────────\n",
    "PREDICTION_KEY = \"5k8oJDDDmqLn5Yy9n1Q16CHetW6H0pvTjFPj1Q4JpQl7dAVJE0WhJQQJ99BEACYeBjFXJ3w3AAAIACOGZmg4\"\n",
    "ENDPOINT_URL = \"https://cv7934-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/92adf90f-3b67-4923-b2eb-1804da244279/detect/iterations/Iteration1/image\"\n",
    "\n",
    "# ─────────────────────────────────────\n",
    "# AI 감지 함수\n",
    "# ─────────────────────────────────────\n",
    "def detect_with_boxes(image: Image.Image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    headers = {\n",
    "        \"Prediction-Key\": PREDICTION_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "    response = requests.post(ENDPOINT_URL, headers=headers, data=buffered.getvalue())\n",
    "    response.raise_for_status()\n",
    "    results = response.json()\n",
    "\n",
    "    image_with_boxes = image.copy()\n",
    "    draw = ImageDraw.Draw(image_with_boxes)\n",
    "    for pred in results[\"predictions\"]:\n",
    "        if pred[\"probability\"] > 0.5:\n",
    "            w, h = image.width, image.height\n",
    "            box = pred[\"boundingBox\"]\n",
    "            left = box[\"left\"] * w\n",
    "            top = box[\"top\"] * h\n",
    "            right = left + box[\"width\"] * w\n",
    "            bottom = top + box[\"height\"] * h\n",
    "            draw.rectangle([left, top, right, bottom], outline=\"red\", width=2)\n",
    "            draw.text((left, top), f\"{pred['tagName']} ({pred['probability']:.2f})\", fill=\"red\")\n",
    "\n",
    "    return image_with_boxes\n",
    "\n",
    "# ─────────────────────────────────────\n",
    "# 이미지 업로드 + AI 감지 실행\n",
    "# ─────────────────────────────────────\n",
    "def handle_uploaded_image(image):\n",
    "    if image is None:\n",
    "        return None, None, None, gr.update(visible=False)\n",
    "\n",
    "    ai_img = detect_with_boxes(image)\n",
    "    annot_input = {\n",
    "        \"image\": np.array(image.convert(\"RGB\")),\n",
    "        \"boxes\": []\n",
    "    }\n",
    "\n",
    "    return ai_img, annot_input, image, gr.update(visible=True)\n",
    "\n",
    "# ─────────────────────────────────────\n",
    "# 겹쳐 시각화\n",
    "# ─────────────────────────────────────\n",
    "def overlap_visualizer(base_img, user_data):\n",
    "    if base_img is None or not user_data:\n",
    "        return None\n",
    "\n",
    "    img = base_img.copy()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    annotations = []\n",
    "    if isinstance(user_data, dict) and \"boxes\" in user_data:\n",
    "        annotations = user_data[\"boxes\"]\n",
    "    elif isinstance(user_data, list):\n",
    "        annotations = user_data\n",
    "\n",
    "    for box in annotations:\n",
    "        x0, y0 = box.get(\"xmin\"), box.get(\"ymin\")\n",
    "        x1, y1 = box.get(\"xmax\"), box.get(\"ymax\")\n",
    "        label = box.get(\"label\", \"사용자\")\n",
    "        if None not in [x0, y0, x1, y1]:\n",
    "            draw.rectangle([x0, y0, x1, y1], outline=\"blue\", width=2)\n",
    "            draw.text((x0, y0 - 10), label, fill=\"blue\")\n",
    "\n",
    "    return img\n",
    "\n",
    "# ─────────────────────────────────────\n",
    "# 저장 함수\n",
    "# ─────────────────────────────────────\n",
    "def save_annotations(annot_data):\n",
    "    print(\"💾 저장 요청됨:\", type(annot_data), annot_data)\n",
    "\n",
    "    try:\n",
    "        if isinstance(annot_data, dict) and \"boxes\" in annot_data:\n",
    "            annotations = annot_data[\"boxes\"]\n",
    "        else:\n",
    "            return f\"❌ 'boxes' 키가 없거나 잘못된 구조입니다.\"\n",
    "\n",
    "        if not annotations:\n",
    "            return \"❌ 박스 정보가 없습니다.\"\n",
    "\n",
    "        now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        file_path = f\"annotation_{now}.json\"\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\"annotations\": annotations}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        return f\"✅ 저장 완료: {file_path}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"❌ 저장 중 오류: {str(e)}\"\n",
    "\n",
    "# ─────────────────────────────────────\n",
    "# Gradio UI\n",
    "# ─────────────────────────────────────\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🚬 담배꽁초 감지 + 사용자 태깅 비교\")\n",
    "\n",
    "    with gr.Row():\n",
    "        image_input = gr.Image(type=\"pil\", label=\"📤 이미지 업로드\")\n",
    "    upload_btn = gr.Button(\"➡️ 감지 시작\")\n",
    "\n",
    "    with gr.Row(visible=False) as result_row:\n",
    "        with gr.Column():\n",
    "            ai_output = gr.Image(label=\"🤖 AI 감지 결과\")\n",
    "            overlap_output = gr.Image(label=\"🎯 겹쳐 보기 (AI + 사용자)\")\n",
    "        with gr.Column():\n",
    "            annotator = image_annotator(\n",
    "                label_list=[\"사용자\"],\n",
    "                label_colors=[(0, 0, 255)],\n",
    "                scale=False\n",
    "            )\n",
    "            save_btn = gr.Button(\"💾 사용자 태깅 결과 저장\")\n",
    "            save_text = gr.Textbox(label=\"📁 저장 상태\")\n",
    "\n",
    "    # 감지 실행 버튼\n",
    "    upload_btn.click(\n",
    "        fn=handle_uploaded_image,\n",
    "        inputs=image_input,\n",
    "        outputs=[ai_output, annotator, image_input, result_row]\n",
    "    )\n",
    "\n",
    "    # 태깅 변경 시 자동 겹쳐 보기 업데이트\n",
    "    annotator.change(\n",
    "        fn=overlap_visualizer,\n",
    "        inputs=[image_input, annotator],\n",
    "        outputs=overlap_output\n",
    "    )\n",
    "\n",
    "    # 저장 버튼 클릭 시\n",
    "    save_btn.click(\n",
    "        fn=save_annotations,\n",
    "        inputs=annotator,\n",
    "        outputs=save_text\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a468a31",
   "metadata": {},
   "source": [
    "## AI와 태깅 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0ec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import io\n",
    "import requests\n",
    "from gradio_image_annotation import image_annotator\n",
    "\n",
    "# 📌 Custom Vision API 설정\n",
    "PREDICTION_KEY = \"5k8oJDDDmqLn5Yy9n1Q16CHetW6H0pvTjFPj1Q4JpQl7dAVJE0WhJQQJ99BEACYeBjFXJ3w3AAAIACOGZmg4\"\n",
    "ENDPOINT_URL = \"https://cv7934-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/92adf90f-3b67-4923-b2eb-1804da244279/detect/iterations/Iteration1/image\"\n",
    "\n",
    "# 🔍 AI 감지 함수\n",
    "def detect_with_boxes(image: Image.Image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    headers = {\n",
    "        \"Prediction-Key\": PREDICTION_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "    response = requests.post(ENDPOINT_URL, headers=headers, data=buffered.getvalue())\n",
    "    results = response.json()\n",
    "\n",
    "    ai_boxes = []\n",
    "    image_with_boxes = image.copy()\n",
    "    draw = ImageDraw.Draw(image_with_boxes)\n",
    "\n",
    "    for pred in results[\"predictions\"]:\n",
    "        if pred[\"probability\"] > 0.5:\n",
    "            w, h = image.width, image.height\n",
    "            box = pred[\"boundingBox\"]\n",
    "            left = int(box[\"left\"] * w)\n",
    "            top = int(box[\"top\"] * h)\n",
    "            right = int((box[\"left\"] + box[\"width\"]) * w)\n",
    "            bottom = int((box[\"top\"] + box[\"height\"]) * h)\n",
    "\n",
    "            ai_boxes.append({\n",
    "                \"label\": pred[\"tagName\"],\n",
    "                \"xmin\": left,\n",
    "                \"ymin\": top,\n",
    "                \"xmax\": right,\n",
    "                \"ymax\": bottom\n",
    "            })\n",
    "\n",
    "            draw.rectangle([left, top, right, bottom], outline=\"red\", width=2)\n",
    "            draw.text((left, top), f\"{pred['tagName']} ({pred['probability']:.2f})\", fill=\"red\")\n",
    "\n",
    "    return image_with_boxes, ai_boxes\n",
    "\n",
    "# 📦 IoU 계산 함수\n",
    "def calculate_iou(boxA, boxB):\n",
    "    xA = max(boxA[\"xmin\"], boxB[\"xmin\"])\n",
    "    yA = max(boxA[\"ymin\"], boxB[\"ymin\"])\n",
    "    xB = min(boxA[\"xmax\"], boxB[\"xmax\"])\n",
    "    yB = min(boxA[\"ymax\"], boxB[\"ymax\"])\n",
    "\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    boxAArea = (boxA[\"xmax\"] - boxA[\"xmin\"]) * (boxA[\"ymax\"] - boxA[\"ymin\"])\n",
    "    boxBArea = (boxB[\"xmax\"] - boxB[\"xmin\"]) * (boxB[\"ymax\"] - boxB[\"ymin\"])\n",
    "    unionArea = float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    if unionArea == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return interArea / unionArea\n",
    "\n",
    "# 📤 업로드 처리\n",
    "def handle_upload(image: Image.Image):\n",
    "    ai_image, ai_boxes = detect_with_boxes(image)\n",
    "\n",
    "    annotator_input = {\n",
    "        \"image\": np.array(image.convert(\"RGB\")),\n",
    "        \"annotations\": []\n",
    "    }\n",
    "\n",
    "    return ai_image, annotator_input, ai_boxes\n",
    "\n",
    "# ✅ IoU 비교\n",
    "def compare_iou(user_data, ai_boxes):\n",
    "    if not user_data or \"boxes\" not in user_data:\n",
    "        return \"❌ 사용자 태깅 없음\"\n",
    "\n",
    "    user_boxes = user_data[\"boxes\"]\n",
    "    if not user_boxes or not ai_boxes:\n",
    "        return \"❌ 비교할 박스 없음\"\n",
    "\n",
    "    ious = []\n",
    "    for user_box in user_boxes:\n",
    "        user = {\n",
    "            \"xmin\": user_box[\"xmin\"],\n",
    "            \"ymin\": user_box[\"ymin\"],\n",
    "            \"xmax\": user_box[\"xmax\"],\n",
    "            \"ymax\": user_box[\"ymax\"]\n",
    "        }\n",
    "        best_iou = max([calculate_iou(user, ai_box) for ai_box in ai_boxes])\n",
    "        ious.append(best_iou)\n",
    "\n",
    "    avg_iou = sum(ious) / len(ious)\n",
    "    return f\"✅ 평균 IoU: {avg_iou:.2f}\"\n",
    "\n",
    "# 🎛️ Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🚬 담배꽁초 감지: AI vs 사용자 태깅\")\n",
    "\n",
    "    image_input = gr.Image(type=\"pil\", label=\"이미지 업로드\")\n",
    "    upload_btn = gr.Button(\"AI 감지 및 태깅 시작\")\n",
    "\n",
    "    with gr.Row(visible=False) as result_row:\n",
    "        ai_result = gr.Image(label=\"🤖 AI 감지 결과 (빨간 박스)\")\n",
    "        annotator = image_annotator(label_list=[\"bungee\"], label_colors=[(0, 0, 255)])\n",
    "\n",
    "    hidden_ai_boxes = gr.State([])  # AI 박스 저장용\n",
    "    compare_btn = gr.Button(\"📐 IoU 비교\")\n",
    "    iou_text = gr.Textbox(label=\"결과\")\n",
    "\n",
    "    upload_btn.click(fn=handle_upload, inputs=image_input, outputs=[ai_result, annotator, hidden_ai_boxes])\n",
    "    upload_btn.click(lambda: gr.update(visible=True), None, result_row)\n",
    "\n",
    "    compare_btn.click(fn=compare_iou, inputs=[annotator, hidden_ai_boxes], outputs=iou_text)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974f1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from gradio_image_annotation import image_annotator\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# Custom Vision API 설정\n",
    "#──────────────────────────────────────────────────────────────\n",
    "PREDICTION_KEY = \"5k8oJDDDmqLn5Yy9n1Q16CHetW6H0pvTjFPj1Q4JpQl7dAVJE0WhJQQJ99BEACYeBjFXJ3w3AAAIACOGZmg4\"\n",
    "ENDPOINT_URL = \"https://cv7934-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/92adf90f-3b67-4923-b2eb-1804da244279/detect/iterations/Iteration1/image\"\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# IoU 계산 함수\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def calculate_iou(boxA, boxB):\n",
    "    xA = max(boxA[\"xmin\"], boxB[\"xmin\"])\n",
    "    yA = max(boxA[\"ymin\"], boxB[\"ymin\"])\n",
    "    xB = min(boxA[\"xmax\"], boxB[\"xmax\"])\n",
    "    yB = min(boxA[\"ymax\"], boxB[\"ymax\"])\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    unionArea = float(\n",
    "        (boxA[\"xmax\"] - boxA[\"xmin\"]) * (boxA[\"ymax\"] - boxA[\"ymin\"]) +\n",
    "        (boxB[\"xmax\"] - boxB[\"xmin\"]) * (boxB[\"ymax\"] - boxB[\"ymin\"]) - interArea\n",
    "    )\n",
    "    return interArea / unionArea if unionArea != 0 else 0\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# AI 감지\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def detect_with_boxes(image: Image.Image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    headers = {\n",
    "        \"Prediction-Key\": PREDICTION_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "    response = requests.post(ENDPOINT_URL, headers=headers, data=buffered.getvalue())\n",
    "    results = response.json()\n",
    "\n",
    "    ai_boxes = []\n",
    "    image_with_boxes = image.copy()\n",
    "    draw = ImageDraw.Draw(image_with_boxes)\n",
    "\n",
    "    for pred in results[\"predictions\"]:\n",
    "        if pred[\"probability\"] > 0.5:\n",
    "            w, h = image.width, image.height\n",
    "            box = pred[\"boundingBox\"]\n",
    "            left = int(box[\"left\"] * w)\n",
    "            top = int(box[\"top\"] * h)\n",
    "            right = int((box[\"left\"] + box[\"width\"]) * w)\n",
    "            bottom = int((box[\"top\"] + box[\"height\"]) * h)\n",
    "\n",
    "            ai_boxes.append({\n",
    "                \"label\": pred[\"tagName\"],\n",
    "                \"xmin\": left,\n",
    "                \"ymin\": top,\n",
    "                \"xmax\": right,\n",
    "                \"ymax\": bottom\n",
    "            })\n",
    "\n",
    "            draw.rectangle([left, top, right, bottom], outline=\"red\", width=2)\n",
    "            draw.text((left, top), f\"{pred['tagName']} ({pred['probability']:.2f})\", fill=\"red\")\n",
    "\n",
    "    return image_with_boxes, ai_boxes\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# 업로드 처리\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def handle_upload(image: Image.Image):\n",
    "    ai_img, ai_boxes = detect_with_boxes(image)\n",
    "    annotator_input = {\n",
    "        \"image\": np.array(image.convert(\"RGB\")),\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    return ai_img, annotator_input, ai_boxes, image\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# 박스 비교 및 시각화\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def compare_boxes(user_data, ai_boxes):\n",
    "    if not user_data or \"boxes\" not in user_data:\n",
    "        return \"❌ 사용자 태깅 없음\", None, []\n",
    "\n",
    "    img_array = user_data[\"image\"]\n",
    "    user_boxes = user_data[\"boxes\"]\n",
    "    img = Image.fromarray(img_array)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    matched_count = 0\n",
    "    results_to_save = []\n",
    "    used_ai = set()\n",
    "    used_user = set()\n",
    "\n",
    "    for u_idx, ubox in enumerate(user_boxes):\n",
    "        user = {\n",
    "            \"xmin\": ubox[\"xmin\"],\n",
    "            \"ymin\": ubox[\"ymin\"],\n",
    "            \"xmax\": ubox[\"xmax\"],\n",
    "            \"ymax\": ubox[\"ymax\"]\n",
    "        }\n",
    "\n",
    "        best_iou = 0\n",
    "        matched_ai_idx = -1\n",
    "        for i, abox in enumerate(ai_boxes):\n",
    "            iou = calculate_iou(user, abox)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                matched_ai_idx = i\n",
    "\n",
    "        if best_iou >= 0.5:\n",
    "            matched_count += 1\n",
    "            used_ai.add(matched_ai_idx)\n",
    "            used_user.add(u_idx)\n",
    "            draw.rectangle([user[\"xmin\"], user[\"ymin\"], user[\"xmax\"], user[\"ymax\"]], outline=\"green\", width=2)\n",
    "        else:\n",
    "            draw.rectangle([user[\"xmin\"], user[\"ymin\"], user[\"xmax\"], user[\"ymax\"]], outline=\"yellow\", width=2)\n",
    "\n",
    "        results_to_save.append({\n",
    "            \"label\": ubox[\"label\"],\n",
    "            \"xmin\": ubox[\"xmin\"],\n",
    "            \"ymin\": ubox[\"ymin\"],\n",
    "            \"xmax\": ubox[\"xmax\"],\n",
    "            \"ymax\": ubox[\"ymax\"],\n",
    "            \"matched\": best_iou >= 0.5,\n",
    "            \"iou\": round(best_iou, 2)\n",
    "        })\n",
    "\n",
    "    for idx, abox in enumerate(ai_boxes):\n",
    "        if idx not in used_ai:\n",
    "            draw.rectangle([abox[\"xmin\"], abox[\"ymin\"], abox[\"xmax\"], abox[\"ymax\"]], outline=\"orange\", width=2)\n",
    "\n",
    "    user_only = len(user_boxes) - matched_count\n",
    "    ai_only = len(ai_boxes) - len(used_ai)\n",
    "\n",
    "    # 점수 계산\n",
    "    score_match = matched_count * 0.5\n",
    "    score_user = user_only * 0.3\n",
    "    score_ai = ai_only * 0.2\n",
    "    total_score = score_match + score_user + score_ai\n",
    "\n",
    "    msg = (\n",
    "        f\"✅ 비교 완료!\\n\"\n",
    "        f\"- 일치한 태그: {matched_count}/{len(user_boxes)}개\\n\"\n",
    "        f\"- 사용자만 태깅한 박스: {user_only}개\\n\"\n",
    "        f\"- AI만 감지한 박스: {ai_only}개\\n\"\n",
    "        f\"\\n\"\n",
    "        f\"📊 총점: {total_score:.1f}점 (일치: {score_match:.1f}, 사용자만: {score_user:.1f}, AI만: {score_ai:.1f})\"\n",
    "    )\n",
    "\n",
    "    return msg, img, results_to_save\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# 결과 저장\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def save_results(image: Image.Image, results_to_save):\n",
    "    os.makedirs(\"saved_images\", exist_ok=True)\n",
    "    filename = f\"saved_images/image_{np.random.randint(100000)}.jpg\"\n",
    "    image.save(filename)\n",
    "\n",
    "    with open(\"saved_annotations.json\", \"a\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"image\": filename, \"annotations\": results_to_save}, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    return f\"💾 저장 완료: {filename}\"\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# Gradio UI\n",
    "#──────────────────────────────────────────────────────────────\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🧪 담배꽁초 감지 비교 (사용자 vs AI)\")\n",
    "\n",
    "    image_input = gr.Image(type=\"pil\", label=\"이미지 업로드\")\n",
    "    start_btn = gr.Button(\"🟦 AI 감지 및 태깅 시작\")\n",
    "\n",
    "    with gr.Row(visible=False) as tag_row:\n",
    "        ai_result = gr.Image(label=\"🤖 AI 감지 결과\")\n",
    "        annotator = image_annotator(label_list=[\"bungee\"], label_colors=[(0, 0, 255)])\n",
    "\n",
    "    compare_btn = gr.Button(\"📐 비교\", visible=False)\n",
    "\n",
    "    with gr.Row(visible=False) as compare_row:\n",
    "        compare_result = gr.Image(label=\"📊 사용자 vs AI 비교 결과\")\n",
    "\n",
    "    compare_text = gr.Textbox(label=\"결과 메시지\", visible=False, lines=6)\n",
    "    save_btn = gr.Button(\"💾 결과 저장\", visible=False)\n",
    "    save_text = gr.Textbox(label=\"저장 메시지\", visible=False)\n",
    "\n",
    "    hidden_ai_boxes = gr.State()\n",
    "    original_image = gr.State()\n",
    "    temp_save_result = gr.State()\n",
    "\n",
    "    start_btn.click(fn=handle_upload,\n",
    "                    inputs=image_input,\n",
    "                    outputs=[ai_result, annotator, hidden_ai_boxes, original_image])\n",
    "    start_btn.click(lambda: (gr.update(visible=True),)*2,\n",
    "                    None, [tag_row, compare_btn])\n",
    "\n",
    "    compare_btn.click(fn=compare_boxes,\n",
    "                      inputs=[annotator, hidden_ai_boxes],\n",
    "                      outputs=[compare_text, compare_result, temp_save_result])\n",
    "    compare_btn.click(lambda: (gr.update(visible=True),)*3,\n",
    "                      None, [compare_text, compare_row, save_btn])\n",
    "\n",
    "    save_btn.click(fn=save_results,\n",
    "                   inputs=[original_image, temp_save_result],\n",
    "                   outputs=save_text)\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
