{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458e4ded",
   "metadata": {},
   "source": [
    "### í•™ìŠµìš© csvíŒŒì¼ ë§Œë“¤ê¸° : clahe ì „ì²˜ë¦¬(ë°ê¸° ì¡°ì •) -> midasë¡œ í‰ê· ê¹Šì´ ì¶”ì • -> custom_visionìœ¼ë¡œ ë°°ìˆ˜êµ¬ ìœ„ì¹˜ ì¶œë ¥ -> csvíŒŒì¼ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•˜ë‚˜ì˜ í´ë”ë§Œ clahe ì „ì²˜ë¦¬ ì²˜ë¦¬\n",
    "# CLAHE + Grayscale ë³€í™˜ (ì–´ë‘ìš´ ë°°ìˆ˜êµ¬ ì£¼ë³€ë„ ë” ëšœë ·í•˜ê²Œ + ROI ë°ê¸° í†µê³„ ì‚°ì¶œìš©) \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# === MiDaS ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ===\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Large\", trust_repo=True)\n",
    "midas.eval()\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
    "transform = midas_transforms.dpt_transform\n",
    "\n",
    "# === Custom Vision ì„¤ì • ===\n",
    "PREDICTION_KEY = \"5sloqMYWiZSpfCd7HZgQ9ZpfuQAXnRWwjSw648WjXGr5Fy5f7imcJQQJ99BFACYeBjFXJ3w3AAAIACOGBDCR\"\n",
    "PREDICTION_URL = \"https://7aiteam05ai012-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/f360eeb2-f8df-441e-8bed-f27d3ef1797a/detect/iterations/Iteration2/image\"\n",
    "\n",
    "# === ë³´ì¡° í•¨ìˆ˜ ===\n",
    "def get_customvision_bboxes(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        headers = {\n",
    "            \"Prediction-Key\": PREDICTION_KEY,\n",
    "            \"Content-Type\": \"application/octet-stream\"\n",
    "        }\n",
    "        response = requests.post(PREDICTION_URL, headers=headers, data=image_file)\n",
    "        response.raise_for_status()\n",
    "        predictions = response.json()[\"predictions\"]\n",
    "        return [p[\"boundingBox\"] for p in predictions if p[\"probability\"] > 0.5]\n",
    "\n",
    "def clahe_normalize(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "def get_bbox_roi(image, bbox, img_w, img_h):\n",
    "    x = int(bbox[\"left\"] * img_w)\n",
    "    y = int(bbox[\"top\"] * img_h)\n",
    "    w = int(bbox[\"width\"] * img_w)\n",
    "    h = int(bbox[\"height\"] * img_h)\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "    return roi, (x, y, w, h)\n",
    "\n",
    "# === ì…ë ¥ & ì¶œë ¥ í´ë” ì„¤ì • ===\n",
    "input_folder = \"medium_clean_100\"                         # ì˜ˆì¸¡ ëŒ€ìƒ ì´ë¯¸ì§€ í´ë” ì…ë ¥!!!!!!\n",
    "output_folder = \"depth_output_medium_clean_100_ver1\"      # ê²°ê³¼ ì €ì¥í•  í´ë” ì…ë ¥!!!!!\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "summary = []\n",
    "\n",
    "# === ì „ì²´ ì´ë¯¸ì§€ ìˆœíšŒ ì²˜ë¦¬ ===\n",
    "for filename in tqdm(os.listdir(input_folder)):\n",
    "    if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, filename)\n",
    "    bgr = cv2.imread(path)\n",
    "    if bgr is None:\n",
    "        continue\n",
    "\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    clahe_img = clahe_normalize(rgb)\n",
    "    gray = cv2.cvtColor(clahe_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # === MiDaS depth ì˜ˆì¸¡ ===\n",
    "    input_tensor = transform(clahe_img)\n",
    "    with torch.no_grad():\n",
    "        pred = midas(input_tensor)\n",
    "        pred = torch.nn.functional.interpolate(\n",
    "            pred.unsqueeze(1), size=rgb.shape[:2], mode=\"bicubic\", align_corners=False\n",
    "        ).squeeze()\n",
    "    depth_map = pred.cpu().numpy()\n",
    "\n",
    "    # === ì‹œê°í™”ìš© ì»¬ëŸ¬ë§µ ===\n",
    "    mean_depth = np.mean(depth_map)\n",
    "    vmin, vmax = max(0, mean_depth - 5), mean_depth + 5\n",
    "    clipped = np.clip(depth_map, vmin, vmax)\n",
    "    norm = ((clipped - vmin) / (vmax - vmin) * 255).astype(np.uint8)\n",
    "    depth_colored = cv2.applyColorMap(norm, cv2.COLORMAP_INFERNO)\n",
    "\n",
    "    # === ì»¤ìŠ¤í…€ë¹„ì „ìœ¼ë¡œ bbox ì˜ˆì¸¡ ===\n",
    "    bboxes = get_customvision_bboxes(path)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        roi_gray, (x, y, w, h) = get_bbox_roi(gray, bbox, rgb.shape[1], rgb.shape[0])\n",
    "        roi_depth, _ = get_bbox_roi(depth_map, bbox, rgb.shape[1], rgb.shape[0])\n",
    "\n",
    "        # ì¤‘ì‹¬ ì¶•ì†Œ (í‘œì¤€í¸ì°¨ ê¸°ë°˜)\n",
    "        if np.std(roi_depth) > 5.0:\n",
    "            x, y = x + w // 4, y + h // 4\n",
    "            w, h = w // 2, h // 2\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_depth = depth_map[y:y + h, x:x + w]\n",
    "\n",
    "        # í†µê³„ ìˆ˜ì§‘\n",
    "        brightness_mean = roi_gray.mean()\n",
    "        brightness_std = roi_gray.std()\n",
    "        depth_mean = roi_depth.mean()\n",
    "        depth_std = roi_depth.std()\n",
    "\n",
    "        # ë°•ìŠ¤ ì‹œê°í™”\n",
    "        cv2.rectangle(depth_colored, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(depth_colored, f\"{depth_mean:.2f}\", (x, y - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "        summary.append({\n",
    "            \"filename\": filename,\n",
    "            \"bbox_index\": i,\n",
    "            \"brightness_mean\": brightness_mean,\n",
    "            \"brightness_std\": brightness_std,\n",
    "            \"depth_mean\": depth_mean,\n",
    "            \"depth_std\": depth_std,\n",
    "            \"x\": x, \"y\": y, \"w\": w, \"h\": h\n",
    "        })\n",
    "\n",
    "    # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥\n",
    "    save_path = os.path.join(output_folder, filename.rsplit('.', 1)[0] + \"_depth.jpg\")\n",
    "    cv2.imwrite(save_path, depth_colored)\n",
    "\n",
    "# === CSV ì €ì¥ ===\n",
    "df = pd.DataFrame(summary)\n",
    "csv_path = os.path.join(output_folder, \"clahe_depth_medium_clean_100_ver1.csv\")          # ìµœì¢… csv íŒŒì¼ëª… ì…ë ¥!!!!!!\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"âœ… ë¶„ì„ ì™„ë£Œ: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fde939",
   "metadata": {},
   "source": [
    "### í•™ìŠµìš© ëª¨ë¸ ë§Œë“¤ê¸° : ìœ„ì—ì„œ ë§Œë“  í•™ìŠµìš© csvíŒŒì¼ ê°€ì ¸ì˜¤ê¸° -> SVR ëª¨ë¸ í•™ìŠµ -> predicted-score ì˜ˆì¸¡ -> ê²°ê³¼ ì €ì¥(csvíŒŒì¼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b12867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ê¸° ê³ ë ¤\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# ğŸ“ í•™ìŠµìš© CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "file_clean = \"depth_output_both_ver1/clahe_depth_m_clean_ver2.csv\"                 # í•™ìŠµìš© csv íŒŒì¼ ê²½ë¡œ ì…ë ¥\n",
    "file_medium_heavy = \"depth_output_both_ver1/clahe_depth_m_heavy_ver2.csv\"          # í•™ìŠµìš© csv íŒŒì¼ ê²½ë¡œ ì…ë ¥\n",
    "file_heavy = \"depth_output_heavy_62_ver1/clahe_depth_combined_heavy_ver1.csv\"      # í•™ìŠµìš© csv íŒŒì¼ ê²½ë¡œ ì…ë ¥\n",
    "\n",
    "df_clean = pd.read_csv(file_clean)\n",
    "df_medium_heavy = pd.read_csv(file_medium_heavy)\n",
    "df_heavy = pd.read_csv(file_heavy)\n",
    "\n",
    "# ğŸ¯ ì…ë ¥ íŠ¹ì„± 4ê°œë¡œ í™•ì¥\n",
    "features = ['brightness_mean', 'brightness_std', 'depth_mean', 'depth_std']\n",
    "\n",
    "X_clean = df_clean[features]\n",
    "X_medium_heavy = df_medium_heavy[features]\n",
    "X_heavy = df_heavy[features]\n",
    "\n",
    "# ğŸ“Œ ë¼ë²¨ë§: Clean=0, Medium=50, Heavy=100\n",
    "y_clean = np.full(len(X_clean), 0)\n",
    "y_medium_heavy = np.full(len(X_medium_heavy), 50)\n",
    "y_heavy = np.full(len(X_heavy), 100)\n",
    "\n",
    "# ğŸ”— ì „ì²´ ë°ì´í„° ë³‘í•©\n",
    "X = pd.concat([X_clean, X_medium_heavy, X_heavy], ignore_index=True)\n",
    "y = np.concatenate([y_clean, y_medium_heavy, y_heavy])\n",
    "\n",
    "# âš™ï¸ SVR ëª¨ë¸ í•™ìŠµ\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = make_pipeline(StandardScaler(), SVR(kernel=\"rbf\", C=100, epsilon=1.0))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# âœ… ëª¨ë¸ ì €ì¥\n",
    "joblib.dump(model, \"svr_pollution_model_4features.pkl\")\n",
    "\n",
    "# ğŸ§  ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\n",
    "predicted_score = model.predict(X)\n",
    "X_result = X.copy()\n",
    "X_result[\"predicted_score\"] = predicted_score\n",
    "X_result.to_csv(\"pollution_score_svr_4features.csv\", index=False)                  \n",
    "\n",
    "# ğŸ“ ì˜ˆì¸¡ ëŒ€ìƒ CSV ë¡œë“œ (test ì´ë¯¸ì§€ìš© clahe + depth ì™„ë£Œëœ CSV)\n",
    "group = pd.read_csv(\"test_ver1/clahe_test_ver1.csv\")                  # ì˜ˆì¸¡í•  csvíŒŒì¼ ê²½ë¡œ ì…ë ¥!!!!!\n",
    "predicted_df = pd.read_csv(\"pollution_score_svr_4features.csv\")\n",
    "\n",
    "# ë³‘í•©: groupì— predicted_score ë¶™ì´ê¸°\n",
    "group_key = group[[\"filename\", \"bbox_index\"]].reset_index(drop=True)\n",
    "group_for_merge = pd.concat([group_key, predicted_df[\"predicted_score\"]], axis=1)\n",
    "group[\"predicted_score\"] = group_for_merge[\"predicted_score\"]\n",
    "\n",
    "# ğŸ’¾ ì €ì¥\n",
    "group.to_csv(\"test_ver1/clahe_test_ver1_with_score.csv\", index=False)       # ì €ì¥í•  csv íŒŒì¼ ê²½ë¡œ ë° ì´ë¦„ ì…ë ¥!!!!!\n",
    "\n",
    "# ğŸ“Š ì‹œê°í™” (ì˜ˆì‹œ: depth ê¸°ì¤€ ì ìˆ˜ ë¶„í¬)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_result[\"depth_mean\"], X_result[\"depth_std\"],\n",
    "            c=X_result[\"predicted_score\"], cmap=\"coolwarm\", edgecolor=\"k\")\n",
    "plt.colorbar(label=\"Predicted Pollution Score (0~100)\")\n",
    "plt.xlabel(\"Depth Mean\")\n",
    "plt.ylabel(\"Depth Std\")\n",
    "plt.title(\"SVR with Brightness + Depth Features\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ í•™ìŠµ + ì˜ˆì¸¡ + ì‹œê°í™” ì™„ë£Œ (ë°ê¸° í¬í•¨ 4 feature ê¸°ë°˜)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285a693",
   "metadata": {},
   "source": [
    "### í…ŒìŠ¤íŠ¸ìš© csvíŒŒì¼ ë§Œë“¤ê¸° : clahe ì „ì²˜ë¦¬(ë°ê¸° ì¡°ì •) -> midasë¡œ í‰ê· ê¹Šì´ ì¶”ì • -> custom_visionìœ¼ë¡œ ë°°ìˆ˜êµ¬ ìœ„ì¹˜ ì¶œë ¥ -> csvíŒŒì¼ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•˜ë‚˜ì˜ í´ë”ë§Œ clahe ì „ì²˜ë¦¬ ì²˜ë¦¬\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# === MiDaS ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ===\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Large\", trust_repo=True)\n",
    "midas.eval()\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
    "transform = midas_transforms.dpt_transform\n",
    "\n",
    "# === Custom Vision ì„¤ì • ===\n",
    "PREDICTION_KEY = \"5sloqMYWiZSpfCd7HZgQ9ZpfuQAXnRWwjSw648WjXGr5Fy5f7imcJQQJ99BFACYeBjFXJ3w3AAAIACOGBDCR\"\n",
    "PREDICTION_URL = \"https://7aiteam05ai012-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/f360eeb2-f8df-441e-8bed-f27d3ef1797a/detect/iterations/Iteration2/image\"\n",
    "\n",
    "# === ë³´ì¡° í•¨ìˆ˜ ===\n",
    "def get_customvision_bboxes(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        headers = {\n",
    "            \"Prediction-Key\": PREDICTION_KEY,\n",
    "            \"Content-Type\": \"application/octet-stream\"\n",
    "        }\n",
    "        response = requests.post(PREDICTION_URL, headers=headers, data=image_file)\n",
    "        response.raise_for_status()\n",
    "        predictions = response.json()[\"predictions\"]\n",
    "        if not predictions:\n",
    "            return []\n",
    "\n",
    "        # ê°€ì¥ ë†’ì€ í™•ë¥  í•˜ë‚˜ë§Œ ì¶”ì¶œ\n",
    "        best = max(predictions, key=lambda x: x[\"probability\"])\n",
    "        if best[\"probability\"] > 0.5:\n",
    "            return [best[\"boundingBox\"]]\n",
    "        else:\n",
    "            return []\n",
    "        # return [p[\"boundingBox\"] for p in predictions if p[\"probability\"] > 0.5]\n",
    "\n",
    "def clahe_normalize(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "def get_bbox_roi(image, bbox, img_w, img_h):\n",
    "    x = int(bbox[\"left\"] * img_w)\n",
    "    y = int(bbox[\"top\"] * img_h)\n",
    "    w = int(bbox[\"width\"] * img_w)\n",
    "    h = int(bbox[\"height\"] * img_h)\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "    return roi, (x, y, w, h)\n",
    "\n",
    "# === ì…ë ¥ & ì¶œë ¥ í´ë” ì„¤ì • ===\n",
    "input_folder = \"test3\"                           # ì˜ˆì¸¡ ëŒ€ìƒ ì´ë¯¸ì§€ í´ë” ì…ë ¥!!!!!\"\n",
    "output_folder = \"test_ver3\"                      # ê²°ê³¼ í´ë” ì…ë ¥!!!!!\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "summary = []\n",
    "\n",
    "# === ì „ì²´ ì´ë¯¸ì§€ ìˆœíšŒ ì²˜ë¦¬ ===\n",
    "for filename in tqdm(os.listdir(input_folder)):\n",
    "    if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, filename)\n",
    "    bgr = cv2.imread(path)\n",
    "    if bgr is None:\n",
    "        continue\n",
    "\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    clahe_img = clahe_normalize(rgb)\n",
    "    gray = cv2.cvtColor(clahe_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # === MiDaS depth ì˜ˆì¸¡ ===\n",
    "    input_tensor = transform(clahe_img)\n",
    "    with torch.no_grad():\n",
    "        pred = midas(input_tensor)\n",
    "        pred = torch.nn.functional.interpolate(\n",
    "            pred.unsqueeze(1), size=rgb.shape[:2], mode=\"bicubic\", align_corners=False\n",
    "        ).squeeze()\n",
    "    depth_map = pred.cpu().numpy()\n",
    "\n",
    "    # === ì‹œê°í™”ìš© ì»¬ëŸ¬ë§µ ===\n",
    "    mean_depth = np.mean(depth_map)\n",
    "    vmin, vmax = max(0, mean_depth - 5), mean_depth + 5\n",
    "    clipped = np.clip(depth_map, vmin, vmax)\n",
    "    norm = ((clipped - vmin) / (vmax - vmin) * 255).astype(np.uint8)\n",
    "    depth_colored = cv2.applyColorMap(norm, cv2.COLORMAP_INFERNO)\n",
    "\n",
    "    # === ì»¤ìŠ¤í…€ë¹„ì „ìœ¼ë¡œ bbox ì˜ˆì¸¡ ===\n",
    "    bboxes = get_customvision_bboxes(path)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        roi_gray, (x, y, w, h) = get_bbox_roi(gray, bbox, rgb.shape[1], rgb.shape[0])\n",
    "        roi_depth, _ = get_bbox_roi(depth_map, bbox, rgb.shape[1], rgb.shape[0])\n",
    "\n",
    "        # ì¤‘ì‹¬ ì¶•ì†Œ (í‘œì¤€í¸ì°¨ ê¸°ë°˜)\n",
    "        if np.std(roi_depth) > 5.0:\n",
    "            x, y = x + w // 4, y + h // 4\n",
    "            w, h = w // 2, h // 2\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_depth = depth_map[y:y + h, x:x + w]\n",
    "\n",
    "        # í†µê³„ ìˆ˜ì§‘\n",
    "        brightness_mean = roi_gray.mean()\n",
    "        brightness_std = roi_gray.std()\n",
    "        depth_mean = roi_depth.mean()\n",
    "        depth_std = roi_depth.std()\n",
    "\n",
    "        # ë°•ìŠ¤ ì‹œê°í™”\n",
    "        cv2.rectangle(depth_colored, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(depth_colored, f\"{depth_mean:.2f}\", (x, y - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "        summary.append({\n",
    "            \"filename\": filename,\n",
    "            \"bbox_index\": i,\n",
    "            \"brightness_mean\": brightness_mean,\n",
    "            \"brightness_std\": brightness_std,\n",
    "            \"depth_mean\": depth_mean,\n",
    "            \"depth_std\": depth_std,\n",
    "            \"x\": x, \"y\": y, \"w\": w, \"h\": h\n",
    "        })\n",
    "\n",
    "    # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥\n",
    "    save_path = os.path.join(output_folder, filename.rsplit('.', 1)[0] + \"_depth.jpg\")\n",
    "    cv2.imwrite(save_path, depth_colored)\n",
    "\n",
    "# === CSV ì €ì¥ ===\n",
    "df = pd.DataFrame(summary)\n",
    "csv_path = os.path.join(output_folder, \"clahe_test_ver3.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"âœ… ë¶„ì„ ì™„ë£Œ: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76056aca",
   "metadata": {},
   "source": [
    "### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ : testìš© csvíŒŒì¼ ì…ë ¥ -> ì´ë¯¸ì§€ë‹¹ ì˜¤ì—¼ìˆ˜ì¹˜ê°’ ì œì¼ë†’ì€ bboxë§Œ ì‹œê°í™” -> predicted_score ê³„ì‚°í•´ì„œ ìµœì¢… ì˜¤ì—¼ìˆ˜ì¹˜ê°’ bbox ì¤‘ì•™ í‘œì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbox ì¤‘ì‹¬ì— ë¹¨ê°„ ê¸€ì”¨ë¡œ ì ìˆ˜ ì‹œê°í™” ì™„ë£Œ\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# === [1] ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ===\n",
    "model = joblib.load(\"svr_pollution_model_4features.pkl\")\n",
    "\n",
    "# === [2] CSV ë¡œë“œ ===\n",
    "csv_path = \"test_ver3/clahe_test_ver3.csv\"                   # testìš© csvíŒŒì¼ ì…ë ¥!!!!!\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# === [3] ì˜ˆì¸¡ ìˆ˜í–‰ ===\n",
    "features = ['brightness_mean', 'brightness_std', 'depth_mean', 'depth_std']\n",
    "X = df[features].values\n",
    "df[\"predicted_score\"] = model.predict(X)\n",
    "\n",
    "# === [4] ì´ë¯¸ì§€ë‹¹ ìµœê³  bboxë§Œ ì‹œê°í™” ===\n",
    "output_folder = \"test_ver3\"                                  # output_folder ì´ë¦„ ì…ë ¥!!!!!\n",
    "\n",
    "for filename, group in df.groupby(\"filename\"):\n",
    "    best_row = group.loc[group[\"predicted_score\"].idxmax()]\n",
    "    score = best_row[\"predicted_score\"]\n",
    "    x, y, w, h = int(best_row.x), int(best_row.y), int(best_row.w), int(best_row.h)\n",
    "\n",
    "    # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "    image_path = os.path.join(output_folder, filename.rsplit('.', 1)[0] + \"_depth.jpg\")\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"âŒ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    # === bbox ê·¸ë¦¬ê¸° ===\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "\n",
    "    # === í…ìŠ¤íŠ¸ ì„¤ì • ===\n",
    "    label = f\"{score:.1f}\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1.8           # ê¸€ì”¨ í¬ê¸° ì¡°ì ˆ (ì ë‹¹íˆ í¼)\n",
    "    font_thickness = 4\n",
    "    text_color = (0, 0, 255)   # ë¹¨ê°„ìƒ‰\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°\n",
    "    text_size, _ = cv2.getTextSize(label, font, font_scale, font_thickness)\n",
    "    text_width, text_height = text_size\n",
    "\n",
    "    # === í…ìŠ¤íŠ¸ ìœ„ì¹˜ (bbox ì¤‘ì•™) ===\n",
    "    text_x = x + (w - text_width) // 2\n",
    "    text_y = y + (h + text_height) // 2\n",
    "\n",
    "    # === ê¸€ì í…Œë‘ë¦¬(ê²€ì •) + ë³¸ë¬¸(ë¹¨ê°•) ===\n",
    "    cv2.putText(img, label, (text_x, text_y), font, font_scale, (0, 0, 0), font_thickness + 2, cv2.LINE_AA)\n",
    "    cv2.putText(img, label, (text_x, text_y), font, font_scale, text_color, font_thickness, cv2.LINE_AA)\n",
    "\n",
    "    # === ì´ë¯¸ì§€ ì €ì¥ ===\n",
    "    save_path = os.path.join(output_folder, filename.rsplit('.', 1)[0] + \"_labeled.jpg\")\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "# === [5] ìµœê³  bboxë§Œ CSV ì €ì¥ ===\n",
    "df_top = df.loc[df.groupby(\"filename\")[\"predicted_score\"].idxmax()].reset_index(drop=True)\n",
    "df_top.to_csv(os.path.join(output_folder, \"clahe_test_best_bbox_only.csv\"), index=False)    \n",
    "\n",
    "print(\"âœ… bbox ì¤‘ì‹¬ì— ë¹¨ê°„ ê¸€ì”¨ë¡œ ì ìˆ˜ ì‹œê°í™” ì™„ë£Œ\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
