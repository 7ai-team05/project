{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458e4ded",
   "metadata": {},
   "source": [
    "### 학습용 csv파일 만들기 : clahe 전처리(밝기 조정) -> midas로 평균깊이 추정 -> custom_vision으로 배수구 위치 출력 -> csv파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 폴더만 clahe 전처리 처리\n",
    "# CLAHE + Grayscale 변환 (어두운 배수구 주변도 더 뚜렷하게 + ROI 밝기 통계 산출용) \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# === MiDaS 모델 불러오기 ===\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Large\", trust_repo=True)\n",
    "midas.eval()\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
    "transform = midas_transforms.dpt_transform\n",
    "\n",
    "# === Custom Vision 설정 ===\n",
    "PREDICTION_KEY = \"5sloqMYWiZSpfCd7HZgQ9ZpfuQAXnRWwjSw648WjXGr5Fy5f7imcJQQJ99BFACYeBjFXJ3w3AAAIACOGBDCR\"\n",
    "PREDICTION_URL = \"https://7aiteam05ai012-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/f360eeb2-f8df-441e-8bed-f27d3ef1797a/detect/iterations/Iteration2/image\"\n",
    "\n",
    "# === 보조 함수 ===\n",
    "def get_customvision_bboxes(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        headers = {\n",
    "            \"Prediction-Key\": PREDICTION_KEY,\n",
    "            \"Content-Type\": \"application/octet-stream\"\n",
    "        }\n",
    "        response = requests.post(PREDICTION_URL, headers=headers, data=image_file)\n",
    "        response.raise_for_status()\n",
    "        predictions = response.json()[\"predictions\"]\n",
    "        return [p[\"boundingBox\"] for p in predictions if p[\"probability\"] > 0.5]\n",
    "\n",
    "def clahe_normalize(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "def get_bbox_roi(image, bbox, img_w, img_h):\n",
    "    x = int(bbox[\"left\"] * img_w)\n",
    "    y = int(bbox[\"top\"] * img_h)\n",
    "    w = int(bbox[\"width\"] * img_w)\n",
    "    h = int(bbox[\"height\"] * img_h)\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "    return roi, (x, y, w, h)\n",
    "\n",
    "# === 입력 & 출력 폴더 설정 ===\n",
    "input_folder = \"medium_clean_100\"                         # 예측 대상 이미지 폴더 입력!!!!!!\n",
    "output_folder = \"depth_output_medium_clean_100_ver1\"      # 결과 저장할 폴더 입력!!!!!\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "summary = []\n",
    "\n",
    "# === 전체 이미지 순회 처리 ===\n",
    "for filename in tqdm(os.listdir(input_folder)):\n",
    "    if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, filename)\n",
    "    bgr = cv2.imread(path)\n",
    "    if bgr is None:\n",
    "        continue\n",
    "\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    clahe_img = clahe_normalize(rgb)\n",
    "    gray = cv2.cvtColor(clahe_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # === MiDaS depth 예측 ===\n",
    "    input_tensor = transform(clahe_img)\n",
    "    with torch.no_grad():\n",
    "        pred = midas(input_tensor)\n",
    "        pred = torch.nn.functional.interpolate(\n",
    "            pred.unsqueeze(1), size=rgb.shape[:2], mode=\"bicubic\", align_corners=False\n",
    "        ).squeeze()\n",
    "    depth_map = pred.cpu().numpy()\n",
    "\n",
    "    # === 시각화용 컬러맵 ===\n",
    "    mean_depth = np.mean(depth_map)\n",
    "    vmin, vmax = max(0, mean_depth - 5), mean_depth + 5\n",
    "    clipped = np.clip(depth_map, vmin, vmax)\n",
    "    norm = ((clipped - vmin) / (vmax - vmin) * 255).astype(np.uint8)\n",
    "    depth_colored = cv2.applyColorMap(norm, cv2.COLORMAP_INFERNO)\n",
    "\n",
    "    # === 커스텀비전으로 bbox 예측 ===\n",
    "    bboxes = get_customvision_bboxes(path)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        roi_gray, (x, y, w, h) = get_bbox_roi(gray, bbox, rgb.shape[1], rgb.shape[0])\n",
    "        roi_depth, _ = get_bbox_roi(depth_map, bbox, rgb.shape[1], rgb.shape[0])\n",
    "\n",
    "        # 중심 축소 (표준편차 기반)\n",
    "        if np.std(roi_depth) > 5.0:\n",
    "            x, y = x + w // 4, y + h // 4\n",
    "            w, h = w // 2, h // 2\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_depth = depth_map[y:y + h, x:x + w]\n",
    "\n",
    "        # 통계 수집\n",
    "        brightness_mean = roi_gray.mean()\n",
    "        brightness_std = roi_gray.std()\n",
    "        depth_mean = roi_depth.mean()\n",
    "        depth_std = roi_depth.std()\n",
    "\n",
    "        # 박스 시각화\n",
    "        cv2.rectangle(depth_colored, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(depth_colored, f\"{depth_mean:.2f}\", (x, y - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "        summary.append({\n",
    "            \"filename\": filename,\n",
    "            \"bbox_index\": i,\n",
    "            \"brightness_mean\": brightness_mean,\n",
    "            \"brightness_std\": brightness_std,\n",
    "            \"depth_mean\": depth_mean,\n",
    "            \"depth_std\": depth_std,\n",
    "            \"x\": x, \"y\": y, \"w\": w, \"h\": h\n",
    "        })\n",
    "\n",
    "    # 시각화 이미지 저장\n",
    "    save_path = os.path.join(output_folder, filename.rsplit('.', 1)[0] + \"_depth.jpg\")\n",
    "    cv2.imwrite(save_path, depth_colored)\n",
    "\n",
    "# === CSV 저장 ===\n",
    "df = pd.DataFrame(summary)\n",
    "csv_path = os.path.join(output_folder, \"clahe_depth_medium_clean_100_ver1.csv\")          # 최종 csv 파일명 입력!!!!!!\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"✅ 분석 완료: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fde939",
   "metadata": {},
   "source": [
    "### 학습용 모델 만들기 : 위에서 만든 학습용 csv파일 가져오기 -> SVR 모델 학습 -> predicted-score 예측 -> 결과 저장(csv파일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b12867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 밝기 고려\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# 📁 학습용 CSV 불러오기\n",
    "file_clean = \"depth_output_both_ver1/clahe_depth_m_clean_ver2.csv\"                 # 학습용 csv 파일 경로 입력\n",
    "file_medium_heavy = \"depth_output_both_ver1/clahe_depth_m_heavy_ver2.csv\"          # 학습용 csv 파일 경로 입력\n",
    "file_heavy = \"depth_output_heavy_62_ver1/clahe_depth_combined_heavy_ver1.csv\"      # 학습용 csv 파일 경로 입력\n",
    "\n",
    "df_clean = pd.read_csv(file_clean)\n",
    "df_medium_heavy = pd.read_csv(file_medium_heavy)\n",
    "df_heavy = pd.read_csv(file_heavy)\n",
    "\n",
    "# 🎯 입력 특성 4개로 확장\n",
    "features = ['brightness_mean', 'brightness_std', 'depth_mean', 'depth_std']\n",
    "\n",
    "X_clean = df_clean[features]\n",
    "X_medium_heavy = df_medium_heavy[features]\n",
    "X_heavy = df_heavy[features]\n",
    "\n",
    "# 📌 라벨링: Clean=0, Medium=50, Heavy=100\n",
    "y_clean = np.full(len(X_clean), 0)\n",
    "y_medium_heavy = np.full(len(X_medium_heavy), 50)\n",
    "y_heavy = np.full(len(X_heavy), 100)\n",
    "\n",
    "# 🔗 전체 데이터 병합\n",
    "X = pd.concat([X_clean, X_medium_heavy, X_heavy], ignore_index=True)\n",
    "y = np.concatenate([y_clean, y_medium_heavy, y_heavy])\n",
    "\n",
    "# ⚙️ SVR 모델 학습\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = make_pipeline(StandardScaler(), SVR(kernel=\"rbf\", C=100, epsilon=1.0))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ✅ 모델 저장\n",
    "joblib.dump(model, \"svr_pollution_model_4features.pkl\")\n",
    "\n",
    "# 🧠 예측 결과 저장\n",
    "predicted_score = model.predict(X)\n",
    "X_result = X.copy()\n",
    "X_result[\"predicted_score\"] = predicted_score\n",
    "X_result.to_csv(\"pollution_score_svr_4features.csv\", index=False)                  \n",
    "\n",
    "# 📁 예측 대상 CSV 로드 (test 이미지용 clahe + depth 완료된 CSV)\n",
    "group = pd.read_csv(\"test_ver1/clahe_test_ver1.csv\")                  # 예측할 csv파일 경로 입력!!!!!\n",
    "predicted_df = pd.read_csv(\"pollution_score_svr_4features.csv\")\n",
    "\n",
    "# 병합: group에 predicted_score 붙이기\n",
    "group_key = group[[\"filename\", \"bbox_index\"]].reset_index(drop=True)\n",
    "group_for_merge = pd.concat([group_key, predicted_df[\"predicted_score\"]], axis=1)\n",
    "group[\"predicted_score\"] = group_for_merge[\"predicted_score\"]\n",
    "\n",
    "# 💾 저장\n",
    "group.to_csv(\"test_ver1/clahe_test_ver1_with_score.csv\", index=False)       # 저장할 csv 파일 경로 및 이름 입력!!!!!\n",
    "\n",
    "# 📊 시각화 (예시: depth 기준 점수 분포)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_result[\"depth_mean\"], X_result[\"depth_std\"],\n",
    "            c=X_result[\"predicted_score\"], cmap=\"coolwarm\", edgecolor=\"k\")\n",
    "plt.colorbar(label=\"Predicted Pollution Score (0~100)\")\n",
    "plt.xlabel(\"Depth Mean\")\n",
    "plt.ylabel(\"Depth Std\")\n",
    "plt.title(\"SVR with Brightness + Depth Features\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ 모델 학습 + 예측 + 시각화 완료 (밝기 포함 4 feature 기반)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285a693",
   "metadata": {},
   "source": [
    "### 테스트용 csv파일 만들기 : clahe 전처리(밝기 조정) -> midas로 평균깊이 추정 -> custom_vision으로 배수구 위치 출력 -> csv파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 폴더만 clahe 전처리 처리\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# === MiDaS 모델 불러오기 ===\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Large\", trust_repo=True)\n",
    "midas.eval()\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
    "transform = midas_transforms.dpt_transform\n",
    "\n",
    "# === Custom Vision 설정 ===\n",
    "PREDICTION_KEY = \"5sloqMYWiZSpfCd7HZgQ9ZpfuQAXnRWwjSw648WjXGr5Fy5f7imcJQQJ99BFACYeBjFXJ3w3AAAIACOGBDCR\"\n",
    "PREDICTION_URL = \"https://7aiteam05ai012-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/f360eeb2-f8df-441e-8bed-f27d3ef1797a/detect/iterations/Iteration2/image\"\n",
    "\n",
    "# === 보조 함수 ===\n",
    "def get_customvision_bboxes(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        headers = {\n",
    "            \"Prediction-Key\": PREDICTION_KEY,\n",
    "            \"Content-Type\": \"application/octet-stream\"\n",
    "        }\n",
    "        response = requests.post(PREDICTION_URL, headers=headers, data=image_file)\n",
    "        response.raise_for_status()\n",
    "        predictions = response.json()[\"predictions\"]\n",
    "        if not predictions:\n",
    "            return []\n",
    "\n",
    "        # 가장 높은 확률 하나만 추출\n",
    "        best = max(predictions, key=lambda x: x[\"probability\"])\n",
    "        if best[\"probability\"] > 0.5:\n",
    "            return [best[\"boundingBox\"]]\n",
    "        else:\n",
    "            return []\n",
    "        # return [p[\"boundingBox\"] for p in predictions if p[\"probability\"] > 0.5]\n",
    "\n",
    "def clahe_normalize(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "def get_bbox_roi(image, bbox, img_w, img_h):\n",
    "    x = int(bbox[\"left\"] * img_w)\n",
    "    y = int(bbox[\"top\"] * img_h)\n",
    "    w = int(bbox[\"width\"] * img_w)\n",
    "    h = int(bbox[\"height\"] * img_h)\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "    return roi, (x, y, w, h)\n",
    "\n",
    "# === 입력 & 출력 폴더 설정 ===\n",
    "input_folder = \"test3\"                           # 예측 대상 이미지 폴더 입력!!!!!\"\n",
    "output_folder = \"test_ver3\"                      # 결과 폴더 입력!!!!!\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "summary = []\n",
    "\n",
    "# === 전체 이미지 순회 처리 ===\n",
    "for filename in tqdm(os.listdir(input_folder)):\n",
    "    if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, filename)\n",
    "    bgr = cv2.imread(path)\n",
    "    if bgr is None:\n",
    "        continue\n",
    "\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    clahe_img = clahe_normalize(rgb)\n",
    "    gray = cv2.cvtColor(clahe_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # === MiDaS depth 예측 ===\n",
    "    input_tensor = transform(clahe_img)\n",
    "    with torch.no_grad():\n",
    "        pred = midas(input_tensor)\n",
    "        pred = torch.nn.functional.interpolate(\n",
    "            pred.unsqueeze(1), size=rgb.shape[:2], mode=\"bicubic\", align_corners=False\n",
    "        ).squeeze()\n",
    "    depth_map = pred.cpu().numpy()\n",
    "\n",
    "    # === 시각화용 컬러맵 ===\n",
    "    mean_depth = np.mean(depth_map)\n",
    "    vmin, vmax = max(0, mean_depth - 5), mean_depth + 5\n",
    "    clipped = np.clip(depth_map, vmin, vmax)\n",
    "    norm = ((clipped - vmin) / (vmax - vmin) * 255).astype(np.uint8)\n",
    "    depth_colored = cv2.applyColorMap(norm, cv2.COLORMAP_INFERNO)\n",
    "\n",
    "    # === 커스텀비전으로 bbox 예측 ===\n",
    "    bboxes = get_customvision_bboxes(path)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        roi_gray, (x, y, w, h) = get_bbox_roi(gray, bbox, rgb.shape[1], rgb.shape[0])\n",
    "        roi_depth, _ = get_bbox_roi(depth_map, bbox, rgb.shape[1], rgb.shape[0])\n",
    "\n",
    "        # 중심 축소 (표준편차 기반)\n",
    "        if np.std(roi_depth) > 5.0:\n",
    "            x, y = x + w // 4, y + h // 4\n",
    "            w, h = w // 2, h // 2\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_depth = depth_map[y:y + h, x:x + w]\n",
    "\n",
    "        # 통계 수집\n",
    "        brightness_mean = roi_gray.mean()\n",
    "        brightness_std = roi_gray.std()\n",
    "        depth_mean = roi_depth.mean()\n",
    "        depth_std = roi_depth.std()\n",
    "\n",
    "        # 박스 시각화\n",
    "        cv2.rectangle(depth_colored, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(depth_colored, f\"{depth_mean:.2f}\", (x, y - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "        summary.append({\n",
    "            \"filename\": filename,\n",
    "            \"bbox_index\": i,\n",
    "            \"brightness_mean\": brightness_mean,\n",
    "            \"brightness_std\": brightness_std,\n",
    "            \"depth_mean\": depth_mean,\n",
    "            \"depth_std\": depth_std,\n",
    "            \"x\": x, \"y\": y, \"w\": w, \"h\": h\n",
    "        })\n",
    "\n",
    "    # 시각화 이미지 저장\n",
    "    save_path = os.path.join(output_folder, filename.rsplit('.', 1)[0] + \"_depth.jpg\")\n",
    "    cv2.imwrite(save_path, depth_colored)\n",
    "\n",
    "# === CSV 저장 ===\n",
    "df = pd.DataFrame(summary)\n",
    "csv_path = os.path.join(output_folder, \"clahe_test_ver3.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"✅ 분석 완료: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76056aca",
   "metadata": {},
   "source": [
    "### 테스트 실행 : test용 csv파일 입력 -> 이미지당 오염수치값 제일높은 bbox만 시각화 -> predicted_score 계산해서 최종 오염수치값 bbox 중앙 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbox 중심에 빨간 글씨로 점수 시각화 완료\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# === [1] 모델 불러오기 ===\n",
    "model = joblib.load(\"svr_pollution_model_4features.pkl\")\n",
    "\n",
    "# === [2] CSV 로드 ===\n",
    "csv_path = \"test_ver3/clahe_test_ver3.csv\"                   # test용 csv파일 입력!!!!!\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# === [3] 예측 수행 ===\n",
    "features = ['brightness_mean', 'brightness_std', 'depth_mean', 'depth_std']\n",
    "X = df[features].values\n",
    "df[\"predicted_score\"] = model.predict(X)\n",
    "\n",
    "# === [4] 이미지당 최고 bbox만 시각화 ===\n",
    "output_folder = \"test_ver3\"                                  # output_folder 이름 입력!!!!!\n",
    "\n",
    "for filename, group in df.groupby(\"filename\"):\n",
    "    best_row = group.loc[group[\"predicted_score\"].idxmax()]\n",
    "    score = best_row[\"predicted_score\"]\n",
    "    x, y, w, h = int(best_row.x), int(best_row.y), int(best_row.w), int(best_row.h)\n",
    "\n",
    "    # 이미지 로드\n",
    "    image_path = os.path.join(output_folder, filename.rsplit('.', 1)[0] + \"_depth.jpg\")\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"❌ 이미지 불러오기 실패: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    # === bbox 그리기 ===\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "\n",
    "    # === 텍스트 설정 ===\n",
    "    label = f\"{score:.1f}\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1.8           # 글씨 크기 조절 (적당히 큼)\n",
    "    font_thickness = 4\n",
    "    text_color = (0, 0, 255)   # 빨간색\n",
    "\n",
    "    # 텍스트 크기 계산\n",
    "    text_size, _ = cv2.getTextSize(label, font, font_scale, font_thickness)\n",
    "    text_width, text_height = text_size\n",
    "\n",
    "    # === 텍스트 위치 (bbox 중앙) ===\n",
    "    text_x = x + (w - text_width) // 2\n",
    "    text_y = y + (h + text_height) // 2\n",
    "\n",
    "    # === 글자 테두리(검정) + 본문(빨강) ===\n",
    "    cv2.putText(img, label, (text_x, text_y), font, font_scale, (0, 0, 0), font_thickness + 2, cv2.LINE_AA)\n",
    "    cv2.putText(img, label, (text_x, text_y), font, font_scale, text_color, font_thickness, cv2.LINE_AA)\n",
    "\n",
    "    # === 이미지 저장 ===\n",
    "    save_path = os.path.join(output_folder, filename.rsplit('.', 1)[0] + \"_labeled.jpg\")\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "# === [5] 최고 bbox만 CSV 저장 ===\n",
    "df_top = df.loc[df.groupby(\"filename\")[\"predicted_score\"].idxmax()].reset_index(drop=True)\n",
    "df_top.to_csv(os.path.join(output_folder, \"clahe_test_best_bbox_only.csv\"), index=False)    \n",
    "\n",
    "print(\"✅ bbox 중심에 빨간 글씨로 점수 시각화 완료\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
