{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import folium\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from gradio_image_annotation import image_annotator\n",
    "from PIL.ExifTags import TAGS\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# 이미지 처리\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def process_image(image_path) :\n",
    "    # 이미지가 삭제된 경우, 모든 셋팅 초기화\n",
    "    if image_path is None :\n",
    "        return '', gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
    "\n",
    "    # 이미지 빗물받이 여부 판단\n",
    "    service_or_not_label, service_or_not_probability = predict_with_api(image_path)\n",
    "    is_valid = service_or_not_label == 'service'\n",
    "    validation_msg = f'✅유효한 사진입니다. (예측 : {(service_or_not_probability * 100) :.0f}%)' if is_valid else '🚫유효하지 않은 사진입니다.'\n",
    "\n",
    "    # 빗물받이가 아닌 경우,\n",
    "    if not is_valid :\n",
    "        return validation_msg, gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), ''\n",
    "    \n",
    "    # 빗물받이인 경우,\n",
    "    # 1. 심각도 예측    \n",
    "    severity_label, severity_probability = predict_with_api(image_path, 'severity')\n",
    "    is_clean = severity_label == 'clean'\n",
    "    result_msg = f'🟢 깨끗 ({(severity_probability * 100) :.0f}%)' if is_clean else f'🟡 주의 요망 ({severity_label} : {(severity_probability * 100) :.0f}%)'\n",
    "    \n",
    "    # 2. GPS 정보 추출\n",
    "    gps = get_image_gps(image_path)\n",
    "    # 서울 중심\n",
    "    map = folium.Map(location=[37.566535, 126.9779692], zoom_start=11)\n",
    "    folium.Marker(location=[gps[0], gps[1]], icon=folium.Icon(color='red', icon='star')).add_to(map)\n",
    "    map_html = map._repr_html_()\n",
    "\n",
    "    # 안전신문고 버튼\n",
    "    report_btn = '''\n",
    "        <a href=\"https://www.safetyreport.go.kr\" target=\"_blank\" style=\"display: block; border-radius: 6px; padding: 15px; background: #e4e4e7; color: black; font-weight: bold; text-align: center; text-decoration: none;\">\n",
    "            안전신문고에 신고하러 가기\n",
    "        </a>\n",
    "    '''\n",
    "\n",
    "    return validation_msg, gr.update(value=result_msg, visible=True), gr.update(value=map_html, visible=True), gr.update(value=report_btn, visible=True)\n",
    "\n",
    "\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# 이미지 위치 정보\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def get_image_gps(image_path) :\n",
    "    # 기본값 (서울 중심)\n",
    "    lat, lon = 37.566535, 126.9779692\n",
    "\n",
    "    # 이미지가 삭제된 경우, 모든 셋팅 초기화\n",
    "    if image_path is None :\n",
    "        return lat, lon\n",
    "\n",
    "    # 이미지 불러올 때, 오류가 발생한 경우 기본값 사용\n",
    "    try :\n",
    "        image = Image.open(image_path)\n",
    "        metadata = image._getexif()\n",
    "    except Exception :\n",
    "        return lat, lon\n",
    "\n",
    "    # 메타정보가 없는 경우, 기본값 사용\n",
    "    if not metadata : \n",
    "        return lat, lon\n",
    "\n",
    "    # 메타정보가 있는 경우, 이미지 위치정보 추출\n",
    "    for tag, value in metadata.items() :\n",
    "        decoded = TAGS.get(tag, tag)\n",
    "\n",
    "        if decoded == 'GPSInfo' :\n",
    "            # 위도 (도, 분, 초)\n",
    "            gps_lat = value.get(2)\n",
    "            # 경도 (도, 분, 초)\n",
    "            gps_lon = value.get(4)\n",
    "\n",
    "    try :\n",
    "        if gps_lat and gps_lon : \n",
    "            # 위도\n",
    "            lat = (((gps_lat[2] / 60.0) + gps_lat[1]) / 60.0) + gps_lat[0]\n",
    "            # 경도\n",
    "            lon = (((gps_lon[2] / 60.0) + gps_lon[1]) / 60.0) + gps_lon[0]\n",
    "    except Exception : \n",
    "        pass\n",
    "\n",
    "    return lat, lon\n",
    "\n",
    "\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# 학습 모델 결과 반환\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def predict_with_api(image_path, type='service_or_not') :\n",
    "    # Custom Vision Predictioin 정보\n",
    "    PREDICTION_KEY = {\n",
    "        'service_or_not' : 'BBvYKDdr5RDpSMjG34Z2XXw3hLxzlAQkktCPXwHTLleSagQPHGg0JQQJ99BEACYeBjFXJ3w3AAAIACOGH9bC',\n",
    "        'severity' : 'BBvYKDdr5RDpSMjG34Z2XXw3hLxzlAQkktCPXwHTLleSagQPHGg0JQQJ99BEACYeBjFXJ3w3AAAIACOGH9bC',\n",
    "    }\n",
    "        \n",
    "    ENDPOINT_URL = {\n",
    "        'service_or_not' : 'https://7aiteam05cv-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/58b52583-2cfb-4767-b9e0-8e83032f9d95/classify/iterations/Iteration3/image',\n",
    "        'severity' : 'https://7aiteam05cv-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/ab4cf356-d250-44f4-9221-12c8560bbee1/classify/iterations/Iteration9/image',\n",
    "    }\n",
    "\n",
    "    # API 호출 시, 사용할 헤더 셋팅\n",
    "    headers = {\n",
    "        'Prediction-Key' : PREDICTION_KEY[type],\n",
    "        # 바이너리 이미지 전송\n",
    "        'Content-Type' : 'application/octec-stream'\n",
    "    }\n",
    "\n",
    "    # 전송할 이미지 (바이너리 형태)\n",
    "    byte_data = pil_to_binary(image_path)\n",
    "\n",
    "    # API 호출\n",
    "    response = requests.post(ENDPOINT_URL[type], headers=headers, data=byte_data)\n",
    "    predictions = response.json()['predictions']\n",
    "\n",
    "    # 확률이 가장 높은 예측 항목 선택\n",
    "    top_prediction = max(predictions, key=lambda x : x['probability'])\n",
    "    label = top_prediction['tagName']\n",
    "    probability = top_prediction['probability']\n",
    "\n",
    "    return label, probability\n",
    "\n",
    "\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# PIL 이미지 객체 -> JPEG 형식의 바이너리 데이터로 변환\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def pil_to_binary(image_path) :\n",
    "    image = Image.open(image_path)\n",
    "    buf = io.BytesIO()\n",
    "    image.save(buf, format='JPEG')\n",
    "    byte_data = buf.getvalue()\n",
    "\n",
    "    return byte_data\n",
    "\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# IoU 계산 함수\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def calculate_iou(boxA, boxB):\n",
    "    xA = max(boxA[\"xmin\"], boxB[\"xmin\"])\n",
    "    yA = max(boxA[\"ymin\"], boxB[\"ymin\"])\n",
    "    xB = min(boxA[\"xmax\"], boxB[\"xmax\"])\n",
    "    yB = min(boxA[\"ymax\"], boxB[\"ymax\"])\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    unionArea = float(\n",
    "        (boxA[\"xmax\"] - boxA[\"xmin\"]) * (boxA[\"ymax\"] - boxA[\"ymin\"]) +\n",
    "        (boxB[\"xmax\"] - boxB[\"xmin\"]) * (boxB[\"ymax\"] - boxB[\"ymin\"]) - interArea\n",
    "    )\n",
    "    return interArea / unionArea if unionArea != 0 else 0\n",
    "\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# AI 감지\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def detect_with_boxes(image: Image.Image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    \n",
    "    # Custom Vision API 설정\n",
    "    PREDICTION_KEY = \"5k8oJDDDmqLn5Yy9n1Q16CHetW6H0pvTjFPj1Q4JpQl7dAVJE0WhJQQJ99BEACYeBjFXJ3w3AAAIACOGZmg4\"\n",
    "    ENDPOINT_URL = \"https://cv7934-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/92adf90f-3b67-4923-b2eb-1804da244279/detect/iterations/Iteration1/image\"\n",
    "\n",
    "    headers = {\n",
    "        \"Prediction-Key\": PREDICTION_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "\n",
    "    # Prediction 클라이언트 생성\n",
    "    credentials = ApiKeyCredentials(in_headers={'Prediction-Key' : PREDICTION_KEY})\n",
    "    predictor = CustomVisionPredictionClient(endpoint=ENDPOINT_URL, credentials=credentials)\n",
    "    response = requests.post(ENDPOINT_URL, headers=headers, data=buffered.getvalue())\n",
    "    results = response.json()\n",
    " \n",
    "    ai_boxes = []\n",
    "    image_with_boxes = image.copy()\n",
    "    draw = ImageDraw.Draw(image_with_boxes)\n",
    " \n",
    "    for pred in results[\"predictions\"]:\n",
    "        if pred[\"probability\"] > 0.5:\n",
    "            w, h = image.width, image.height\n",
    "            box = pred[\"boundingBox\"]\n",
    "            left = int(box[\"left\"] * w)\n",
    "            top = int(box[\"top\"] * h)\n",
    "            right = int((box[\"left\"] + box[\"width\"]) * w)\n",
    "            bottom = int((box[\"top\"] + box[\"height\"]) * h)\n",
    " \n",
    "            ai_boxes.append({\n",
    "                \"label\": pred[\"tagName\"],\n",
    "                \"xmin\": left,\n",
    "                \"ymin\": top,\n",
    "                \"xmax\": right,\n",
    "                \"ymax\": bottom\n",
    "            })\n",
    " \n",
    "            draw.rectangle([left, top, right, bottom], outline=\"red\", width=5)\n",
    "            draw.text((left, top), f\"{pred['tagName']} ({pred['probability']:.2f})\", fill=\"red\")\n",
    " \n",
    "    return image_with_boxes, ai_boxes\n",
    "\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# 업로드 처리\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def handle_upload(image: Image.Image):\n",
    "    ai_img, ai_boxes = detect_with_boxes(image)\n",
    "    annotator_input = {\n",
    "        \"image\": np.array(image.convert(\"RGB\")),\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    return ai_img, annotator_input, ai_boxes, image\n",
    "\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# 박스 비교 및 시각화\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def compare_boxes(user_data, ai_boxes):\n",
    "    if not user_data or \"boxes\" not in user_data:\n",
    "        return \"❌ 사용자 태깅 없음\", None, []\n",
    " \n",
    "    img_array = user_data[\"image\"]\n",
    "    user_boxes = user_data[\"boxes\"]\n",
    "    img = Image.fromarray(img_array)\n",
    "    draw = ImageDraw.Draw(img)\n",
    " \n",
    "    matched_count = 0\n",
    "    results_to_save = []\n",
    "    used_ai = set()\n",
    "    used_user = set()\n",
    " \n",
    "    for u_idx, ubox in enumerate(user_boxes):\n",
    "        user = {\n",
    "            \"xmin\": ubox[\"xmin\"],\n",
    "            \"ymin\": ubox[\"ymin\"],\n",
    "            \"xmax\": ubox[\"xmax\"],\n",
    "            \"ymax\": ubox[\"ymax\"]\n",
    "        }\n",
    " \n",
    "        best_iou = 0\n",
    "        matched_ai_idx = -1\n",
    "        for i, abox in enumerate(ai_boxes):\n",
    "            iou = calculate_iou(user, abox)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                matched_ai_idx = i\n",
    " \n",
    "        if best_iou >= 0.5:\n",
    "            matched_count += 1\n",
    "            used_ai.add(matched_ai_idx)\n",
    "            used_user.add(u_idx)\n",
    "            draw.rectangle([user[\"xmin\"], user[\"ymin\"], user[\"xmax\"], user[\"ymax\"]], outline=\"green\", width=5)\n",
    "        else:\n",
    "            draw.rectangle([user[\"xmin\"], user[\"ymin\"], user[\"xmax\"], user[\"ymax\"]], outline=\"yellow\", width=5)\n",
    " \n",
    "        results_to_save.append({\n",
    "            \"label\": ubox[\"label\"],\n",
    "            \"xmin\": ubox[\"xmin\"],\n",
    "            \"ymin\": ubox[\"ymin\"],\n",
    "            \"xmax\": ubox[\"xmax\"],\n",
    "            \"ymax\": ubox[\"ymax\"],\n",
    "            \"matched\": best_iou >= 0.5,\n",
    "            \"iou\": round(best_iou, 2)\n",
    "        })\n",
    " \n",
    "    for idx, abox in enumerate(ai_boxes):\n",
    "        if idx not in used_ai:\n",
    "            draw.rectangle([abox[\"xmin\"], abox[\"ymin\"], abox[\"xmax\"], abox[\"ymax\"]], outline=\"orange\", width=5)\n",
    " \n",
    "    user_only = len(user_boxes) - matched_count\n",
    "    ai_only = len(ai_boxes) - len(used_ai)\n",
    " \n",
    "    # 점수 계산\n",
    "    score_match = matched_count * 0.5\n",
    "    score_user = user_only * 0.3\n",
    "    score_ai = ai_only * 0.2\n",
    "    total_score = score_match + score_user + score_ai\n",
    " \n",
    "    msg = (\n",
    "        f\"✅ 비교 완료!\\n\"\n",
    "        f\"- 일치한 태그: {matched_count}/{len(user_boxes)}개\\n\"\n",
    "        f\"- 사용자만 태깅한 박스: {user_only}개\\n\"\n",
    "        f\"- AI만 감지한 박스: {ai_only}개\\n\"\n",
    "        f\"\\n\"\n",
    "        f\"📊 총점: {total_score:.1f}점 (일치: {score_match:.1f}, 사용자만: {score_user:.1f}, AI만: {score_ai:.1f})\"\n",
    "    )\n",
    " \n",
    "    return msg, img, results_to_save\n",
    "\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# 결과 저장\n",
    "#──────────────────────────────────────────────────────────────\n",
    "def save_results(image: Image.Image, results_to_save):\n",
    "    os.makedirs(\"saved_images\", exist_ok=True)\n",
    "    filename = f\"saved_images/image_{np.random.randint(100000)}.jpg\"\n",
    "    image.save(filename)\n",
    " \n",
    "    with open(\"saved_annotations.json\", \"a\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"image\": filename, \"annotations\": results_to_save}, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    " \n",
    "    return f\"💾 저장 완료: {filename}\"\n",
    "\n",
    "\n",
    "#──────────────────────────────────────────────────────────────\n",
    "# Gradio UI\n",
    "#──────────────────────────────────────────────────────────────\n",
    "with gr.Blocks() as demo :\n",
    "    gr.Markdown('## 🚧 격자형 빗물받이에 특화된 시범 서비스입니다.')\n",
    "\n",
    "    with gr.Tabs() :\n",
    "        # 분류 (clean/heavy) 탭\n",
    "        with gr.Tab('📸') :\n",
    "            gr.Markdown('## 🧹 빗물받이 청결도 판별 (AI)')\n",
    "\n",
    "            # 이미지 메타정보를 사용하기 위해서 type='filepath' 로 지정\n",
    "            image_input = gr.Image(type='filepath', label='사진을 올려주세요.')\n",
    "            validation = gr.Textbox(label='이미지 확인')\n",
    "            prediction = gr.Textbox(label='오염 심각도 확인', visible=False)\n",
    "            map = gr.HTML(visible=False)\n",
    "            report_btn = gr.HTML(visible=False)\n",
    "\n",
    "            # 이미지 업로드\n",
    "            image_input.change(\n",
    "                fn=process_image,\n",
    "                inputs=image_input,\n",
    "                outputs=[validation, prediction, map, report_btn]\n",
    "            )\n",
    "\n",
    "            gr.Markdown(\"## 🧪 담배꽁초 감지 비교 (사용자 vs AI)\")\n",
    "\n",
    "            image_input = gr.Image(type=\"pil\", label=\"이미지 업로드\")\n",
    "            start_btn = gr.Button(\"🟦 AI 감지 및 태깅 시작\")\n",
    "        \n",
    "            with gr.Row(visible=False) as tag_row:\n",
    "                ai_result = gr.Image(label=\"🤖 AI 감지 결과\")\n",
    "                annotator = image_annotator(\n",
    "                    label_list=['cigarette', 'plastic waste', 'paper waste', 'natural object', 'other trash'],\n",
    "                    label_colors=[(255, 0, 0), (0, 0, 255), (0, 255, 0), (255, 0, 255), (255, 255, 255)],\n",
    "                    removable = True\n",
    "                )\n",
    "        \n",
    "            compare_btn = gr.Button(\"📐 비교\", visible=False)\n",
    "        \n",
    "            # 사용자 vs AI 비교 영역\n",
    "            with gr.Row(visible=False) as compare_row:\n",
    "                compare_result = gr.Image(label=\"📊 사용자 vs AI 비교 결과\")\n",
    "        \n",
    "            compare_text = gr.Textbox(label=\"결과 메시지\", visible=False, lines=6)\n",
    "            save_btn = gr.Button(\"💾 결과 저장\", visible=False)\n",
    "            save_text = gr.Textbox(label=\"저장 메시지\", visible=False)\n",
    "        \n",
    "            # global 변수\n",
    "            hidden_ai_boxes = gr.State()\n",
    "            original_image = gr.State()\n",
    "            temp_save_result = gr.State()\n",
    "        \n",
    "            # AI 감지 및 태깅\n",
    "            start_btn.click(\n",
    "                fn=handle_upload,\n",
    "                inputs=image_input,\n",
    "                outputs=[ai_result, annotator, hidden_ai_boxes, original_image]\n",
    "            )\n",
    "\n",
    "            start_btn.click(\n",
    "                lambda: (gr.update(visible=True),)*2,\n",
    "                None,\n",
    "                [tag_row, compare_btn]\n",
    "            )\n",
    "        \n",
    "            # 사용자 vs AI 비교\n",
    "            compare_btn.click(\n",
    "                fn=compare_boxes,\n",
    "                inputs=[annotator, hidden_ai_boxes],\n",
    "                outputs=[compare_text, compare_result, temp_save_result]\n",
    "            )\n",
    "\n",
    "            compare_btn.click(\n",
    "                lambda: (gr.update(visible=True),)*3,\n",
    "                None,\n",
    "                [compare_text, compare_row, save_btn]\n",
    "            )\n",
    "        \n",
    "            # 결과 저장\n",
    "            save_btn.click(\n",
    "                fn=save_results,\n",
    "                inputs=[original_image, temp_save_result],\n",
    "                outputs=save_text\n",
    "            )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
