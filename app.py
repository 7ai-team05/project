import gradio as gr
import folium
import io
import os
import requests
import json
import numpy as np
from PIL import Image, ImageDraw
from gradio_image_annotation import image_annotator
from PIL.ExifTags import TAGS
from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient
from msrest.authentication import ApiKeyCredentials

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì´ë¯¸ì§€ ì²˜ë¦¬
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_image(image_path) :
    # ì´ë¯¸ì§€ê°€ ì‚­ì œëœ ê²½ìš°, ëª¨ë“  ì…‹íŒ… ì´ˆê¸°í™”
    if image_path is None :
        return '', gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)

    # ì´ë¯¸ì§€ ë¹—ë¬¼ë°›ì´ ì—¬ë¶€ íŒë‹¨
    service_or_not_label, service_or_not_probability = predict_with_api(image_path)
    is_valid = service_or_not_label == 'service'
    validation_msg = f'âœ…ìœ íš¨í•œ ì‚¬ì§„ì…ë‹ˆë‹¤. (ì˜ˆì¸¡ : {(service_or_not_probability * 100) :.0f}%)' if is_valid else 'ğŸš«ìœ íš¨í•˜ì§€ ì•Šì€ ì‚¬ì§„ì…ë‹ˆë‹¤.'

    # ë¹—ë¬¼ë°›ì´ê°€ ì•„ë‹Œ ê²½ìš°,
    if not is_valid :
        return validation_msg, gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), ''
    
    # ë¹—ë¬¼ë°›ì´ì¸ ê²½ìš°,
    # 1. ì‹¬ê°ë„ ì˜ˆì¸¡    
    severity_label, severity_probability = predict_with_api(image_path, 'severity')
    is_clean = severity_label == 'clean'
    result_msg = f'ğŸŸ¢ ê¹¨ë— ({(severity_probability * 100) :.0f}%)' if is_clean else f'ğŸŸ¡ ì£¼ì˜ ìš”ë§ ({severity_label} : {(severity_probability * 100) :.0f}%)'
    
    # 2. GPS ì •ë³´ ì¶”ì¶œ
    gps = get_image_gps(image_path)
    # ì„œìš¸ ì¤‘ì‹¬
    map = folium.Map(location=[37.566535, 126.9779692], zoom_start=11)
    folium.Marker(location=[gps[0], gps[1]], icon=folium.Icon(color='red', icon='star')).add_to(map)
    map_html = map._repr_html_()

    # ì•ˆì „ì‹ ë¬¸ê³  ë²„íŠ¼
    report_btn = '''
        <a href="https://www.safetyreport.go.kr" target="_blank" style="display: block; border-radius: 6px; padding: 15px; background: #e4e4e7; color: black; font-weight: bold; text-align: center; text-decoration: none;">
            ì•ˆì „ì‹ ë¬¸ê³ ì— ì‹ ê³ í•˜ëŸ¬ ê°€ê¸°
        </a>
    '''

    return validation_msg, gr.update(value=result_msg, visible=True), gr.update(value=map_html, visible=True), gr.update(value=report_btn, visible=True)


#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì´ë¯¸ì§€ ìœ„ì¹˜ ì •ë³´
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_image_gps(image_path) :
    # ê¸°ë³¸ê°’ (ì„œìš¸ ì¤‘ì‹¬)
    lat, lon = 37.566535, 126.9779692

    # ì´ë¯¸ì§€ê°€ ì‚­ì œëœ ê²½ìš°, ëª¨ë“  ì…‹íŒ… ì´ˆê¸°í™”
    if image_path is None :
        return lat, lon

    # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¬ ë•Œ, ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
    try :
        image = Image.open(image_path)
        metadata = image._getexif()
    except Exception :
        return lat, lon

    # ë©”íƒ€ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°, ê¸°ë³¸ê°’ ì‚¬ìš©
    if not metadata : 
        return lat, lon

    # ë©”íƒ€ì •ë³´ê°€ ìˆëŠ” ê²½ìš°, ì´ë¯¸ì§€ ìœ„ì¹˜ì •ë³´ ì¶”ì¶œ
    for tag, value in metadata.items() :
        decoded = TAGS.get(tag, tag)

        if decoded == 'GPSInfo' :
            # ìœ„ë„ (ë„, ë¶„, ì´ˆ)
            gps_lat = value.get(2)
            # ê²½ë„ (ë„, ë¶„, ì´ˆ)
            gps_lon = value.get(4)

    try :
        if gps_lat and gps_lon : 
            # ìœ„ë„
            lat = (((gps_lat[2] / 60.0) + gps_lat[1]) / 60.0) + gps_lat[0]
            # ê²½ë„
            lon = (((gps_lon[2] / 60.0) + gps_lon[1]) / 60.0) + gps_lon[0]
    except Exception : 
        pass

    return lat, lon


#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•™ìŠµ ëª¨ë¸ ê²°ê³¼ ë°˜í™˜
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def predict_with_api(image_path, type='service_or_not') :
    # Custom Vision Predictioin ì •ë³´
    PREDICTION_KEY = {
        'service_or_not' : 'BBvYKDdr5RDpSMjG34Z2XXw3hLxzlAQkktCPXwHTLleSagQPHGg0JQQJ99BEACYeBjFXJ3w3AAAIACOGH9bC',
        'severity' : 'BBvYKDdr5RDpSMjG34Z2XXw3hLxzlAQkktCPXwHTLleSagQPHGg0JQQJ99BEACYeBjFXJ3w3AAAIACOGH9bC',
    }
        
    ENDPOINT_URL = {
        'service_or_not' : 'https://7aiteam05cv-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/58b52583-2cfb-4767-b9e0-8e83032f9d95/classify/iterations/Iteration3/image',
        'severity' : 'https://7aiteam05cv-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/ab4cf356-d250-44f4-9221-12c8560bbee1/classify/iterations/Iteration9/image',
    }

    # API í˜¸ì¶œ ì‹œ, ì‚¬ìš©í•  í—¤ë” ì…‹íŒ…
    headers = {
        'Prediction-Key' : PREDICTION_KEY[type],
        # ë°”ì´ë„ˆë¦¬ ì´ë¯¸ì§€ ì „ì†¡
        'Content-Type' : 'application/octec-stream'
    }

    # ì „ì†¡í•  ì´ë¯¸ì§€ (ë°”ì´ë„ˆë¦¬ í˜•íƒœ)
    byte_data = pil_to_binary(image_path)

    # API í˜¸ì¶œ
    response = requests.post(ENDPOINT_URL[type], headers=headers, data=byte_data)
    predictions = response.json()['predictions']

    # í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ì˜ˆì¸¡ í•­ëª© ì„ íƒ
    top_prediction = max(predictions, key=lambda x : x['probability'])
    label = top_prediction['tagName']
    probability = top_prediction['probability']

    return label, probability


#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PIL ì´ë¯¸ì§€ ê°ì²´ -> JPEG í˜•ì‹ì˜ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¡œ ë³€í™˜
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def pil_to_binary(image_path) :
    image = Image.open(image_path)
    buf = io.BytesIO()
    image.save(buf, format='JPEG')
    byte_data = buf.getvalue()

    return byte_data

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# IoU ê³„ì‚° í•¨ìˆ˜
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def calculate_iou(boxA, boxB):
    xA = max(boxA["xmin"], boxB["xmin"])
    yA = max(boxA["ymin"], boxB["ymin"])
    xB = min(boxA["xmax"], boxB["xmax"])
    yB = min(boxA["ymax"], boxB["ymax"])
    interArea = max(0, xB - xA) * max(0, yB - yA)
    unionArea = float(
        (boxA["xmax"] - boxA["xmin"]) * (boxA["ymax"] - boxA["ymin"]) +
        (boxB["xmax"] - boxB["xmin"]) * (boxB["ymax"] - boxB["ymin"]) - interArea
    )
    return interArea / unionArea if unionArea != 0 else 0

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AI ê°ì§€
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_with_boxes(image: Image.Image):
    buffered = io.BytesIO()
    image.save(buffered, format="JPEG")
    
    # Custom Vision API ì„¤ì •
    PREDICTION_KEY = "5k8oJDDDmqLn5Yy9n1Q16CHetW6H0pvTjFPj1Q4JpQl7dAVJE0WhJQQJ99BEACYeBjFXJ3w3AAAIACOGZmg4"
    ENDPOINT_URL = "https://cv7934-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/92adf90f-3b67-4923-b2eb-1804da244279/detect/iterations/Iteration1/image"

    headers = {
        "Prediction-Key": PREDICTION_KEY,
        "Content-Type": "application/octet-stream"
    }

    # Prediction í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    credentials = ApiKeyCredentials(in_headers={'Prediction-Key' : PREDICTION_KEY})
    predictor = CustomVisionPredictionClient(endpoint=ENDPOINT_URL, credentials=credentials)
    response = requests.post(ENDPOINT_URL, headers=headers, data=buffered.getvalue())
    results = response.json()
 
    ai_boxes = []
    image_with_boxes = image.copy()
    draw = ImageDraw.Draw(image_with_boxes)
 
    for pred in results["predictions"]:
        if pred["probability"] > 0.5:
            w, h = image.width, image.height
            box = pred["boundingBox"]
            left = int(box["left"] * w)
            top = int(box["top"] * h)
            right = int((box["left"] + box["width"]) * w)
            bottom = int((box["top"] + box["height"]) * h)
 
            ai_boxes.append({
                "label": pred["tagName"],
                "xmin": left,
                "ymin": top,
                "xmax": right,
                "ymax": bottom
            })
 
            draw.rectangle([left, top, right, bottom], outline="red", width=5)
            draw.text((left, top), f"{pred['tagName']} ({pred['probability']:.2f})", fill="red")
 
    return image_with_boxes, ai_boxes

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—…ë¡œë“œ ì²˜ë¦¬
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def handle_upload(image: Image.Image):
    ai_img, ai_boxes = detect_with_boxes(image)
    annotator_input = {
        "image": np.array(image.convert("RGB")),
        "annotations": []
    }
    return ai_img, annotator_input, ai_boxes, image

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°•ìŠ¤ ë¹„êµ ë° ì‹œê°í™”
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def compare_boxes(user_data, ai_boxes):
    if not user_data or "boxes" not in user_data:
        return "âŒ ì‚¬ìš©ì íƒœê¹… ì—†ìŒ", None, []
 
    img_array = user_data["image"]
    user_boxes = user_data["boxes"]
    img = Image.fromarray(img_array)
    draw = ImageDraw.Draw(img)
 
    matched_count = 0
    results_to_save = []
    used_ai = set()
    used_user = set()
 
    for u_idx, ubox in enumerate(user_boxes):
        user = {
            "xmin": ubox["xmin"],
            "ymin": ubox["ymin"],
            "xmax": ubox["xmax"],
            "ymax": ubox["ymax"]
        }
 
        best_iou = 0
        matched_ai_idx = -1
        for i, abox in enumerate(ai_boxes):
            iou = calculate_iou(user, abox)
            if iou > best_iou:
                best_iou = iou
                matched_ai_idx = i
 
        if best_iou >= 0.5:
            matched_count += 1
            used_ai.add(matched_ai_idx)
            used_user.add(u_idx)
            draw.rectangle([user["xmin"], user["ymin"], user["xmax"], user["ymax"]], outline="green", width=5)
        else:
            draw.rectangle([user["xmin"], user["ymin"], user["xmax"], user["ymax"]], outline="yellow", width=5)
 
        results_to_save.append({
            "label": ubox["label"],
            "xmin": ubox["xmin"],
            "ymin": ubox["ymin"],
            "xmax": ubox["xmax"],
            "ymax": ubox["ymax"],
            "matched": best_iou >= 0.5,
            "iou": round(best_iou, 2)
        })
 
    for idx, abox in enumerate(ai_boxes):
        if idx not in used_ai:
            draw.rectangle([abox["xmin"], abox["ymin"], abox["xmax"], abox["ymax"]], outline="orange", width=5)
 
    user_only = len(user_boxes) - matched_count
    ai_only = len(ai_boxes) - len(used_ai)
 
    # ì ìˆ˜ ê³„ì‚°
    score_match = matched_count * 0.5
    score_user = user_only * 0.3
    score_ai = ai_only * 0.2
    total_score = score_match + score_user + score_ai
 
    msg = (
        f"âœ… ë¹„êµ ì™„ë£Œ!\n"
        f"- ì¼ì¹˜í•œ íƒœê·¸: {matched_count}/{len(user_boxes)}ê°œ\n"
        f"- ì‚¬ìš©ìë§Œ íƒœê¹…í•œ ë°•ìŠ¤: {user_only}ê°œ\n"
        f"- AIë§Œ ê°ì§€í•œ ë°•ìŠ¤: {ai_only}ê°œ\n"
        f"\n"
        f"ğŸ“Š ì´ì : {total_score:.1f}ì  (ì¼ì¹˜: {score_match:.1f}, ì‚¬ìš©ìë§Œ: {score_user:.1f}, AIë§Œ: {score_ai:.1f})"
    )
 
    return msg, img, results_to_save

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²°ê³¼ ì €ì¥
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def save_results(image: Image.Image, results_to_save):
    os.makedirs("saved_images", exist_ok=True)
    filename = f"saved_images/image_{np.random.randint(100000)}.jpg"
    image.save(filename)
 
    with open("saved_annotations.json", "a", encoding="utf-8") as f:
        json.dump({"image": filename, "annotations": results_to_save}, f, ensure_ascii=False)
        f.write("\n")
 
    return f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {filename}"


#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gradio UI
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with gr.Blocks() as demo :
    gr.Markdown('## ğŸš§ ê²©ìí˜• ë¹—ë¬¼ë°›ì´ì— íŠ¹í™”ëœ ì‹œë²” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.')

    with gr.Tabs() :
        # ë¶„ë¥˜ (clean/heavy) íƒ­
        with gr.Tab('ğŸ“¸') :
            gr.Markdown('## ğŸ§¹ ë¹—ë¬¼ë°›ì´ ì²­ê²°ë„ íŒë³„ (AI)')

            # ì´ë¯¸ì§€ ë©”íƒ€ì •ë³´ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ type='filepath' ë¡œ ì§€ì •
            image_input = gr.Image(type='filepath', label='ì‚¬ì§„ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.')
            validation = gr.Textbox(label='ì´ë¯¸ì§€ í™•ì¸')
            prediction = gr.Textbox(label='ì˜¤ì—¼ ì‹¬ê°ë„ í™•ì¸', visible=False)
            map = gr.HTML(visible=False)
            report_btn = gr.HTML(visible=False)

            # ì´ë¯¸ì§€ ì—…ë¡œë“œ
            image_input.change(
                fn=process_image,
                inputs=image_input,
                outputs=[validation, prediction, map, report_btn]
            )

        # ê°œì²´ ê°ì§€ (ë‹´ë°°ê½ì´ˆ) íƒ­
        with gr.Tab('ğŸ”') :
            gr.Markdown("## ğŸ§ª ë‹´ë°°ê½ì´ˆ ê°ì§€ ë¹„êµ (ì‚¬ìš©ì vs AI)")

            image_input = gr.Image(type="pil", label="ì´ë¯¸ì§€ ì—…ë¡œë“œ")
            start_btn = gr.Button("ğŸŸ¦ AI ê°ì§€ ë° íƒœê¹… ì‹œì‘")
        
            with gr.Row(visible=False) as tag_row:
                ai_result = gr.Image(label="ğŸ¤– AI ê°ì§€ ê²°ê³¼")
                annotator = image_annotator(
                    label_list=['cigarette', 'plastic waste', 'paper waste', 'natural object', 'other trash'],
                    label_colors=[(255, 0, 0), (0, 0, 255), (0, 255, 0), (255, 0, 255), (255, 255, 255)]
                )
        
            compare_btn = gr.Button("ğŸ“ ë¹„êµ", visible=False)
        
            # ì‚¬ìš©ì vs AI ë¹„êµ ì˜ì—­
            with gr.Row(visible=False) as compare_row:
                compare_result = gr.Image(label="ğŸ“Š ì‚¬ìš©ì vs AI ë¹„êµ ê²°ê³¼")
        
            compare_text = gr.Textbox(label="ê²°ê³¼ ë©”ì‹œì§€", visible=False, lines=6)
            save_btn = gr.Button("ğŸ’¾ ê²°ê³¼ ì €ì¥", visible=False)
            save_text = gr.Textbox(label="ì €ì¥ ë©”ì‹œì§€", visible=False)
        
            # global ë³€ìˆ˜
            hidden_ai_boxes = gr.State()
            original_image = gr.State()
            temp_save_result = gr.State()
        
            # AI ê°ì§€ ë° íƒœê¹…
            start_btn.click(
                fn=handle_upload,
                inputs=image_input,
                outputs=[ai_result, annotator, hidden_ai_boxes, original_image]
            )

            start_btn.click(
                lambda: (gr.update(visible=True),)*2,
                None,
                [tag_row, compare_btn]
            )
        
            # ì‚¬ìš©ì vs AI ë¹„êµ
            compare_btn.click(
                fn=compare_boxes,
                inputs=[annotator, hidden_ai_boxes],
                outputs=[compare_text, compare_result, temp_save_result]
            )

            compare_btn.click(
                lambda: (gr.update(visible=True),)*3,
                None,
                [compare_text, compare_row, save_btn]
            )
        
            # ê²°ê³¼ ì €ì¥
            save_btn.click(
                fn=save_results,
                inputs=[original_image, temp_save_result],
                outputs=save_text
            )

demo.launch()