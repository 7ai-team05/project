{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fc7ecb",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af063223",
   "metadata": {},
   "source": [
    "### 각 이미지 ROI에 대한 밝기/깊이 기반의 통계적 파생 피처 계산 및 머신러닝 입력용 매트릭스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a910f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ img_folder unique: ['clean_120_ver1' 'medium_clean_117_ver1' 'medium_heavy_110_ver1'\n",
      " 'heavy_122_ver1']\n",
      "▶ sample file exists: True\n",
      "✅ 최종 피처 행/열: (468, 16)\n"
     ]
    }
   ],
   "source": [
    "# 1. csv 파일 병합\n",
    "# 2. 폴더명 보정\n",
    "# 3. 파일명에 _depth 접미사 추가\n",
    "# 4. ROI(관심영역) 이미지 불러오기 및 파생 피처 계산\n",
    "# 5. 최종 DataFrame 및 피처 매트릭스 생성\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# 1) CSV 합치기\n",
    "csv_info = {\n",
    "    \"clean\":        (\"clean_120_ver1/clahe_clean_120_ver1.csv\",        \"clean_120_ver1\"),\n",
    "    \"medium_clean\": (\"medium_clean_117_ver1/medium_clean_117_ver1.csv\",    \"medium_clean_117\"),\n",
    "    \"medium_heavy\": (\"medium_heavy_110_ver1/medium_heavy_110_ver1.csv\",    \"medium_heavy_110\"),\n",
    "    \"heavy\":        (\"heavy_122_ver1/clahe_heavy_122_ver1.csv\",                  \"heavy_122_ver1\"),\n",
    "}\n",
    "df_list = []\n",
    "for cls, (csv_path, folder) in csv_info.items():\n",
    "    tmp = pd.read_csv(csv_path)\n",
    "    tmp[\"class\"]      = cls\n",
    "    tmp[\"img_folder\"] = folder\n",
    "    df_list.append(tmp)\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 2) img_folder 값 교정\n",
    "df_all.loc[df_all['img_folder']==\"medium_clean_117\", \"img_folder\"] = \"medium_clean_117_ver1\"\n",
    "df_all.loc[df_all['img_folder']==\"medium_heavy_110\", \"img_folder\"] = \"medium_heavy_110_ver1\"\n",
    "# (실제 폴더명으로 정확히 매칭)\n",
    "\n",
    "# 3) filename에 _depth 붙이기\n",
    "def fix_fn(fn):\n",
    "    base, ext = os.path.splitext(fn)\n",
    "    return fn if base.endswith(\"_depth\") else f\"{base}_depth{ext}\"\n",
    "\n",
    "df_all['filename'] = df_all['filename'].apply(fix_fn)\n",
    "\n",
    "# 확인\n",
    "print(\"▶ img_folder unique:\", df_all['img_folder'].unique())\n",
    "print(\"▶ sample file exists:\",\n",
    "      os.path.exists(os.path.join(df_all.loc[0,'img_folder'], df_all.loc[0,'filename'])))\n",
    "\n",
    "# --- 이제 파생 피처 계산(위에서 짠 코드) ---\n",
    "\n",
    "# 4) 파생 피처용 리스트 초기화\n",
    "trimmed_means, depth_bright_ratios = [], []\n",
    "brightness_stds, depth_stds = [], []\n",
    "hist_feats, valid_idx, missing = [], [], []\n",
    "\n",
    "for idx, row in df_all.iterrows():\n",
    "    img_path = os.path.join(row.img_folder, row.filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        missing.append(img_path)\n",
    "        continue\n",
    "\n",
    "    x,y,w,h = map(int, row[['x','y','w','h']])\n",
    "    roi = cv2.cvtColor(img[y:y+h, x:x+w], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 통계\n",
    "    bm, bs = roi.mean(), roi.std()\n",
    "    dm, ds = row.depth_mean, row.depth_std\n",
    "    flat = np.sort(roi.flatten())\n",
    "    lo, hi = int(len(flat)*0.05), int(len(flat)*0.95)\n",
    "    tm = flat[lo:hi].mean()\n",
    "    ratio = dm/(bm+1e-6)\n",
    "    hist, _ = np.histogram(roi.flatten(), bins=10, range=(0,255))\n",
    "\n",
    "    trimmed_means.append(tm)\n",
    "    depth_bright_ratios.append(ratio)\n",
    "    brightness_stds.append(bs)\n",
    "    depth_stds.append(ds)\n",
    "    hist_feats.append(hist/hist.sum())\n",
    "\n",
    "    valid_idx.append(idx)\n",
    "\n",
    "# 5) df_all 재정의 및 X 생성\n",
    "df_all = df_all.loc[valid_idx].reset_index(drop=True)\n",
    "df_all['brightness_std']      = brightness_stds\n",
    "df_all['depth_std']           = depth_stds\n",
    "df_all['bright_trimmed_mean'] = trimmed_means\n",
    "df_all['depth_bright_ratio']  = depth_bright_ratios\n",
    "\n",
    "hist_feats = np.vstack(hist_feats)\n",
    "for i in range(10):\n",
    "    df_all[f'bright_hist_{i}'] = hist_feats[:,i]\n",
    "\n",
    "feature_cols = [\n",
    "    'brightness_mean','brightness_std','depth_mean','depth_std',\n",
    "    'bright_trimmed_mean','depth_bright_ratio'\n",
    "] + [f'bright_hist_{i}' for i in range(10)]\n",
    "X = df_all[feature_cols]\n",
    "print(\"✅ 최종 피처 행/열:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb4aa61",
   "metadata": {},
   "source": [
    "### 불균형 데이터 처리 -> 하이퍼파라미터 튜닝,평가 및 학습된 파이프라인 요소를 재사용 가능한 형태(.pkl)로 내보내는 전체 워크플로우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7920e36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params: {'clf__max_depth': None, 'clf__n_estimators': 200}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.00      0.00      0.00         0\n",
      "         Mid       0.77      0.71      0.74        14\n",
      "        High       0.84      0.88      0.86        24\n",
      "\n",
      "    accuracy                           0.82        38\n",
      "   macro avg       0.54      0.53      0.53        38\n",
      "weighted avg       0.81      0.82      0.81        38\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0]\n",
      " [ 0 10  4]\n",
      " [ 0  3 21]]\n",
      "✅ Scaler(saved as scaler.pkl) and Classifier(saved as rf_classifier.pkl) saved.\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 로드 및 라벨링\n",
    "# 2. 훈련/테스트 데이터 분할(8:2)\n",
    "# 3. 오버샘플링 설정 (중간 클래스(1, 'Mid')만 200개 샘플이 되도록)\n",
    "# 4. Imbalanced-Learn 파이프라인 구성\n",
    "# 5. 하이퍼파라미터 탐색\n",
    "# 6. 모델 평가 (최적 파라미터 출력, 테스트 세트에 대한 분류 리포트와 혼동 행렬 출력)\n",
    "# 7. 최종 모델/스케일러 저장(그리드의 best_estimator_ 에서 스케일러(scaler.pkl)와 분류기(rf_classifier.pkl)를 분리해 joblib.dump로 파일 저장\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import joblib\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1) 데이터 & 피처 준비\n",
    "df_all = pd.read_csv(\"all_with_score_and_class.csv\")  # 파생 피처 포함된 CSV\n",
    "feature_cols = [\n",
    "    'brightness_mean','brightness_std','depth_mean','depth_std',\n",
    "    'bright_trimmed_mean','depth_bright_ratio'\n",
    "] + [f'bright_hist_{i}' for i in range(10)]\n",
    "X = df_all[feature_cols]\n",
    "y = df_all['label4'].map(lambda l: 0 if l <= 33 else (1 if l <= 66 else 2))\n",
    "\n",
    "# 2) Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Mid(1)만 오버샘플링\n",
    "ros = RandomOverSampler(sampling_strategy={1:200}, random_state=42)\n",
    "\n",
    "# 4) imblearn Pipeline 구성\n",
    "pipe = ImbPipeline([\n",
    "    ('oversample', ros),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 5) GridSearchCV로 하이퍼파라미터 탐색\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth':    [None, 10],\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=1,    # 병렬 off\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 6) 평가\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(\n",
    "    y_test, y_pred,\n",
    "    labels=[0,1,2],\n",
    "    target_names=['Low','Mid','High'],\n",
    "    zero_division=0\n",
    "))\n",
    "print(\"Confusion Matrix:\\n\",\n",
    "      confusion_matrix(y_test, y_pred, labels=[0,1,2]))\n",
    "\n",
    "# 7) 학습된 스케일러·분류기 분리 저장\n",
    "best_pipe = grid.best_estimator_\n",
    "scaler     = best_pipe.named_steps['scaler']\n",
    "clf        = best_pipe.named_steps['clf']\n",
    "\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(clf,    \"rf_classifier.pkl\")\n",
    "print(\"✅ Scaler(saved as scaler.pkl) and Classifier(saved as rf_classifier.pkl) saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb8ebb",
   "metadata": {},
   "source": [
    "### 잔차 기반 보정 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba41a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Mid 샘플이 0개로 부족하여 보정 모델 학습을 건너뜁니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\code_project1\\project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 잔차 기반 보정 모델 학습\n",
    "\n",
    "# 1. 회귀모델 로드\n",
    "# 2. 데이터 준비 (파생 피처를 포함한 전체데이터 읽어와서 리스트에 명시된 밝기/깊이 통계피처로 설명 변수와 원본연속 레이블을 준비)\n",
    "# 3. 초기 예측 및 클래스화 (회귀모델로 연속 값 pred4예측, 예측값을 <=33 -> 클래스 0(“Low”), 34~66 → 1(“Mid”), >66 → 2(“High”)로 매핑해 init_cls 생성)\n",
    "# 4. Mid 클래스 오분류 샘플 식별 (실제 y4==33인(정상 Mid) 샘플 중에서, 초기 분류(init_cls)가 2(“High”)인 경우만 need_corr=1로 표시)\n",
    "# 5. 보정 모델 학습 조건 확인 (Mid 샘플 개수가 2개 미만이면 학습을 건너뜀)\n",
    "# 6. 보정용 데이터 분할 & 모델 학습 (Mid 샘플만 골라 설명 변수 Xc, 타깃(need_corr)으로 설정 -> 80/20 stratified split 후 StandardScaler → LogisticRegression 파이프라인(corr_pipe)을 학습)\n",
    "# 7. 평가 및 저장 (테스트 파트에서 classification_report 출력/ 학습된 보정 분류기(corr_pipe)를 correction_clf.pkl로 저장)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 회귀 모델 로드 (예: best_lgb_pipeline.pkl)\n",
    "reg = joblib.load(\"best_lgb_pipeline.pkl\")\n",
    "\n",
    "# 전체 피처 & 레이블\n",
    "df_all = pd.read_csv(\"all_with_score_and_class.csv\")\n",
    "feature_cols = [\n",
    "    'brightness_mean','brightness_std','depth_mean','depth_std',\n",
    "    'bright_trimmed_mean','depth_bright_ratio'\n",
    "] + [f'bright_hist_{i}' for i in range(10)]\n",
    "X_all = df_all[feature_cols]\n",
    "y4    = df_all['label4']\n",
    "pred4 = reg.predict(X_all)\n",
    "\n",
    "# 3) 초기 클래스화 및 Mid 오분류 표시\n",
    "init_cls = np.where(pred4 <= 33, 0, np.where(pred4 <= 66, 1, 2))\n",
    "mask_mid = (y4 == 33)\n",
    "need_corr = np.zeros(len(init_cls), dtype=int)\n",
    "need_corr[mask_mid & (init_cls == 2)] = 1\n",
    "\n",
    "# 4) Mid 샘플 개수 확인\n",
    "mid_count = mask_mid.sum()\n",
    "if mid_count < 2:\n",
    "    print(f\"⚠️ Mid 샘플이 {mid_count}개로 부족하여 보정 모델 학습을 건너뜁니다.\")\n",
    "else:\n",
    "    # 보정 데이터 분할\n",
    "    Xc = X_all[mask_mid]\n",
    "    yc = need_corr[mask_mid]\n",
    "    Xc_tr, Xc_te, yc_tr, yc_te = train_test_split(\n",
    "        Xc, yc, test_size=0.2, random_state=42,\n",
    "        stratify=yc if yc.sum() > 1 else None\n",
    "    )\n",
    "\n",
    "    # 보정 분류기 학습\n",
    "    corr_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression())\n",
    "    ])\n",
    "    corr_pipe.fit(Xc_tr, yc_tr)\n",
    "\n",
    "    # 평가\n",
    "    print(classification_report(yc_te, corr_pipe.predict(Xc_te), zero_division=0))\n",
    "\n",
    "    # 저장\n",
    "    joblib.dump(corr_pipe, \"correction_clf.pkl\")\n",
    "    print(\"✅ correction_clf.pkl 생성 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7befb2",
   "metadata": {},
   "source": [
    "### 4개의 주요 피처만을 사용해 오염도 점수(또는 레이블)를 예측한느 랜덤포레스트 회귀모델 학습 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab8419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 4-피처 전용 모델 저장 완료: rf_4feat_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 로드\n",
    "# 2. 입력 피처(X) / 타깃(y) 분리\n",
    "# 3. 학습/테스트 데이터 분할\n",
    "# 4. 파이프라인 구성\n",
    "# 5. 모델 학습\n",
    "# 6. 모델 저장\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(\"all_with_score_and_class.csv\")\n",
    "\n",
    "# 4개 피처 & 레이블\n",
    "X4 = df[['brightness_mean','brightness_std','depth_mean','depth_std']]\n",
    "y4 = df['label4']\n",
    "\n",
    "# 학습/테스트 분할\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(\n",
    "    X4, y4, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 파이프라인 정의\n",
    "pipe4 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestRegressor(n_estimators=200, random_state=42))\n",
    "])\n",
    "\n",
    "# 학습\n",
    "pipe4.fit(X4_train, y4_train)\n",
    "\n",
    "# 저장\n",
    "joblib.dump(pipe4, \"rf_4feat_pipeline.pkl\")\n",
    "print(\"✅ 4-피처 전용 모델 저장 완료: rf_4feat_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f27d1",
   "metadata": {},
   "source": [
    "# test 파일 전처리 (csv변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c064ddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\USER/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "Using cache found in C:\\Users\\USER/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "100%|██████████| 43/43 [03:02<00:00,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 분석 완료: test4_ver1\\clahe_test_midas_test4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 설정\n",
    "# 2. 이미지 전처리 및 변환\n",
    "# 3. custom vision으로 객체 감지\n",
    "# 4. 결과 저장\n",
    "\n",
    "# 하나의 폴더만 clahe 전처리 처리\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# === MiDaS 모델 불러오기 ===\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Large\", trust_repo=True)\n",
    "midas.eval()\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\", trust_repo=True)\n",
    "transform = midas_transforms.dpt_transform\n",
    "\n",
    "# === Custom Vision 설정 ===\n",
    "PREDICTION_KEY = \"5sloqMYWiZSpfCd7HZgQ9ZpfuQAXnRWwjSw648WjXGr5Fy5f7imcJQQJ99BFACYeBjFXJ3w3AAAIACOGBDCR\"\n",
    "PREDICTION_URL = \"https://7aiteam05ai012-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/f360eeb2-f8df-441e-8bed-f27d3ef1797a/detect/iterations/Iteration2/image\"\n",
    "\n",
    "# === 보조 함수 ===\n",
    "def get_customvision_bboxes(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        headers = {\n",
    "            \"Prediction-Key\": PREDICTION_KEY,\n",
    "            \"Content-Type\": \"application/octet-stream\"\n",
    "        }\n",
    "        response = requests.post(PREDICTION_URL, headers=headers, data=image_file)\n",
    "        response.raise_for_status()\n",
    "        predictions = response.json()[\"predictions\"]\n",
    "        if not predictions:\n",
    "            return []\n",
    "\n",
    "        # 가장 높은 확률 하나만 추출\n",
    "        best = max(predictions, key=lambda x: x[\"probability\"])\n",
    "        if best[\"probability\"] > 0.5:\n",
    "            return [best[\"boundingBox\"]]\n",
    "        else:\n",
    "            return []\n",
    "        # return [p[\"boundingBox\"] for p in predictions if p[\"probability\"] > 0.5]\n",
    "\n",
    "def clahe_normalize(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "def get_bbox_roi(image, bbox, img_w, img_h):\n",
    "    x = int(bbox[\"left\"] * img_w)\n",
    "    y = int(bbox[\"top\"] * img_h)\n",
    "    w = int(bbox[\"width\"] * img_w)\n",
    "    h = int(bbox[\"height\"] * img_h)\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "    return roi, (x, y, w, h)\n",
    "\n",
    "# === 입력 & 출력 폴더 설정 ===\n",
    "input_folder = \"test4\"           # 예측 대상 이미지 폴더           # \"사용자 입력!!!!!\"\n",
    "output_folder = \"test4_ver1\"         # \"사용자 입력!!!!!\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "summary = []\n",
    "\n",
    "# === 전체 이미지 순회 처리 ===\n",
    "for filename in tqdm(os.listdir(input_folder)):\n",
    "    if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, filename)\n",
    "    bgr = cv2.imread(path)\n",
    "    if bgr is None:\n",
    "        continue\n",
    "\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    clahe_img = clahe_normalize(rgb)\n",
    "    gray = cv2.cvtColor(clahe_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # === MiDaS depth 예측 ===\n",
    "    input_tensor = transform(clahe_img)\n",
    "    with torch.no_grad():\n",
    "        pred = midas(input_tensor)\n",
    "        pred = torch.nn.functional.interpolate(\n",
    "            pred.unsqueeze(1), size=rgb.shape[:2], mode=\"bicubic\", align_corners=False\n",
    "        ).squeeze()\n",
    "    depth_map = pred.cpu().numpy()\n",
    "\n",
    "    # === 시각화용 컬러맵 ===\n",
    "    mean_depth = np.mean(depth_map)\n",
    "    vmin, vmax = max(0, mean_depth - 5), mean_depth + 5\n",
    "    clipped = np.clip(depth_map, vmin, vmax)\n",
    "    norm = ((clipped - vmin) / (vmax - vmin) * 255).astype(np.uint8)\n",
    "    depth_colored = cv2.applyColorMap(norm, cv2.COLORMAP_INFERNO)\n",
    "\n",
    "    # === 커스텀비전으로 bbox 예측 ===\n",
    "    bboxes = get_customvision_bboxes(path)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        roi_gray, (x, y, w, h) = get_bbox_roi(gray, bbox, rgb.shape[1], rgb.shape[0])\n",
    "        roi_depth, _ = get_bbox_roi(depth_map, bbox, rgb.shape[1], rgb.shape[0])\n",
    "\n",
    "        # 중심 축소 (표준편차 기반)\n",
    "        if np.std(roi_depth) > 5.0:\n",
    "            x, y = x + w // 4, y + h // 4\n",
    "            w, h = w // 2, h // 2\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_depth = depth_map[y:y + h, x:x + w]\n",
    "\n",
    "        # 통계 수집\n",
    "        brightness_mean = roi_gray.mean()\n",
    "        brightness_std = roi_gray.std()\n",
    "        depth_mean = roi_depth.mean()\n",
    "        depth_std = roi_depth.std()\n",
    "\n",
    "        # 박스 시각화\n",
    "        cv2.rectangle(depth_colored, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(depth_colored, f\"{depth_mean:.2f}\", (x, y - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "        summary.append({\n",
    "            \"filename\": filename,\n",
    "            \"bbox_index\": i,\n",
    "            \"brightness_mean\": brightness_mean,\n",
    "            \"brightness_std\": brightness_std,\n",
    "            \"depth_mean\": depth_mean,\n",
    "            \"depth_std\": depth_std,\n",
    "            \"x\": x, \"y\": y, \"w\": w, \"h\": h\n",
    "        })\n",
    "\n",
    "    # 시각화 이미지 저장\n",
    "    save_path = os.path.join(output_folder, filename.rsplit('.', 1)[0] + \"_depth.jpg\")\n",
    "    cv2.imwrite(save_path, depth_colored)\n",
    "\n",
    "# === CSV 저장 ===\n",
    "df = pd.DataFrame(summary)\n",
    "csv_path = os.path.join(output_folder, \"clahe_test_midas_test4.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"✅ 분석 완료: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cb112c",
   "metadata": {},
   "source": [
    "# test 파일 4개 피처 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a3885966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 4-피처 추론 완료 → 4feat_inference.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# 모델 로드\n",
    "pipe4 = joblib.load(\"rf_4feat_pipeline.pkl\")\n",
    "\n",
    "# 테스트 CSV\n",
    "df_test = pd.read_csv(\"test4_ver1/clahe_test_midas_test4.csv\")\n",
    "\n",
    "# 4개 피처 입력\n",
    "X4_new = df_test[['brightness_mean','brightness_std','depth_mean','depth_std']]\n",
    "\n",
    "# 예측\n",
    "scores = pipe4.predict(X4_new)\n",
    "df_test['pred_score']  = scores\n",
    "df_test['pred_class3'] = np.where(scores<=33, 'Low',\n",
    "                           np.where(scores<=66, 'Mid', 'High'))\n",
    "\n",
    "# 결과 저장\n",
    "df_test.to_csv(\"test4_ver1/4feat_inference.csv\", index=False)\n",
    "print(\"✅ 4-피처 추론 완료 → 4feat_inference.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee055f71",
   "metadata": {},
   "source": [
    "# TEST 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e3915979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[121]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m plt.show()\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 5) 혼동행렬 시각화\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m cm = \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpred_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpred_class3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mLow\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mHigh\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m plt.figure()\n\u001b[32m     28\u001b[39m plt.imshow(cm, cmap=\u001b[33m'\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Desktop\\code_project1\\project\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Desktop\\code_project1\\project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:467\u001b[39m, in \u001b[36mconfusion_matrix\u001b[39m\u001b[34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m    420\u001b[39m     {\n\u001b[32m    421\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    430\u001b[39m     y_true, y_pred, *, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, labels=\u001b[38;5;28;01mNone\u001b[39;00m, samplewise=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    431\u001b[39m ):\n\u001b[32m    432\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute a confusion matrix for each class or sample.\u001b[39;00m\n\u001b[32m    433\u001b[39m \n\u001b[32m    434\u001b[39m \u001b[33;03m    .. versionadded:: 0.21\u001b[39;00m\n\u001b[32m    435\u001b[39m \n\u001b[32m    436\u001b[39m \u001b[33;03m    Compute class-wise (default) or sample-wise (samplewise=True) multilabel\u001b[39;00m\n\u001b[32m    437\u001b[39m \u001b[33;03m    confusion matrix to evaluate the accuracy of a classification, and output\u001b[39;00m\n\u001b[32m    438\u001b[39m \u001b[33;03m    confusion matrices for each class or sample.\u001b[39;00m\n\u001b[32m    439\u001b[39m \n\u001b[32m    440\u001b[39m \u001b[33;03m    In multilabel confusion matrix :math:`MCM`, the count of true negatives\u001b[39;00m\n\u001b[32m    441\u001b[39m \u001b[33;03m    is :math:`MCM_{:,0,0}`, false negatives is :math:`MCM_{:,1,0}`,\u001b[39;00m\n\u001b[32m    442\u001b[39m \u001b[33;03m    true positives is :math:`MCM_{:,1,1}` and false positives is\u001b[39;00m\n\u001b[32m    443\u001b[39m \u001b[33;03m    :math:`MCM_{:,0,1}`.\u001b[39;00m\n\u001b[32m    444\u001b[39m \n\u001b[32m    445\u001b[39m \u001b[33;03m    Multiclass data will be treated as if binarized under a one-vs-rest\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[33;03m    transformation. Returned confusion matrices will be in the order of\u001b[39;00m\n\u001b[32m    447\u001b[39m \u001b[33;03m    sorted unique labels in the union of (y_true, y_pred).\u001b[39;00m\n\u001b[32m    448\u001b[39m \n\u001b[32m    449\u001b[39m \u001b[33;03m    Read more in the :ref:`User Guide <multilabel_confusion_matrix>`.\u001b[39;00m\n\u001b[32m    450\u001b[39m \n\u001b[32m    451\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m    452\u001b[39m \u001b[33;03m    ----------\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[33;03m    y_true : {array-like, sparse matrix} of shape (n_samples, n_outputs) or \\\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[33;03m            (n_samples,)\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[33;03m        Ground truth (correct) target values.\u001b[39;00m\n\u001b[32m    456\u001b[39m \n\u001b[32m    457\u001b[39m \u001b[33;03m    y_pred : {array-like, sparse matrix} of shape (n_samples, n_outputs) or \\\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[33;03m            (n_samples,)\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[33;03m        Estimated targets as returned by a classifier.\u001b[39;00m\n\u001b[32m    460\u001b[39m \n\u001b[32m    461\u001b[39m \u001b[33;03m    sample_weight : array-like of shape (n_samples,), default=None\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[33;03m        Sample weights.\u001b[39;00m\n\u001b[32m    463\u001b[39m \n\u001b[32m    464\u001b[39m \u001b[33;03m    labels : array-like of shape (n_classes,), default=None\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[33;03m        A list of classes or column indices to select some (or to force\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[33;03m        inclusion of classes absent from the data).\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m \n\u001b[32m    468\u001b[39m \u001b[33;03m    samplewise : bool, default=False\u001b[39;00m\n\u001b[32m    469\u001b[39m \u001b[33;03m        In the multilabel case, this calculates a confusion matrix per sample.\u001b[39;00m\n\u001b[32m    470\u001b[39m \n\u001b[32m    471\u001b[39m \u001b[33;03m    Returns\u001b[39;00m\n\u001b[32m    472\u001b[39m \u001b[33;03m    -------\u001b[39;00m\n\u001b[32m    473\u001b[39m \u001b[33;03m    multi_confusion : ndarray of shape (n_outputs, 2, 2)\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m        A 2x2 confusion matrix corresponding to each output in the input.\u001b[39;00m\n\u001b[32m    475\u001b[39m \u001b[33;03m        When calculating class-wise multi_confusion (default), then\u001b[39;00m\n\u001b[32m    476\u001b[39m \u001b[33;03m        n_outputs = n_labels; when calculating sample-wise multi_confusion\u001b[39;00m\n\u001b[32m    477\u001b[39m \u001b[33;03m        (samplewise=True), n_outputs = n_samples. If ``labels`` is defined,\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[33;03m        the results will be returned in the order specified in ``labels``,\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[33;03m        otherwise the results will be returned in sorted order by default.\u001b[39;00m\n\u001b[32m    480\u001b[39m \n\u001b[32m    481\u001b[39m \u001b[33;03m    See Also\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m    --------\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m    confusion_matrix : Compute confusion matrix to evaluate the accuracy of a\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[33;03m        classifier.\u001b[39;00m\n\u001b[32m    485\u001b[39m \n\u001b[32m    486\u001b[39m \u001b[33;03m    Notes\u001b[39;00m\n\u001b[32m    487\u001b[39m \u001b[33;03m    -----\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    The `multilabel_confusion_matrix` calculates class-wise or sample-wise\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    multilabel confusion matrices, and in multiclass tasks, labels are\u001b[39;00m\n\u001b[32m    490\u001b[39m \u001b[33;03m    binarized under a one-vs-rest way; while\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[33;03m    :func:`~sklearn.metrics.confusion_matrix` calculates one confusion matrix\u001b[39;00m\n\u001b[32m    492\u001b[39m \u001b[33;03m    for confusion between every two classes.\u001b[39;00m\n\u001b[32m    493\u001b[39m \n\u001b[32m    494\u001b[39m \u001b[33;03m    Examples\u001b[39;00m\n\u001b[32m    495\u001b[39m \u001b[33;03m    --------\u001b[39;00m\n\u001b[32m    496\u001b[39m \u001b[33;03m    Multilabel-indicator case:\u001b[39;00m\n\u001b[32m    497\u001b[39m \n\u001b[32m    498\u001b[39m \u001b[33;03m    >>> import numpy as np\u001b[39;00m\n\u001b[32m    499\u001b[39m \u001b[33;03m    >>> from sklearn.metrics import multilabel_confusion_matrix\u001b[39;00m\n\u001b[32m    500\u001b[39m \u001b[33;03m    >>> y_true = np.array([[1, 0, 1],\u001b[39;00m\n\u001b[32m    501\u001b[39m \u001b[33;03m    ...                    [0, 1, 0]])\u001b[39;00m\n\u001b[32m    502\u001b[39m \u001b[33;03m    >>> y_pred = np.array([[1, 0, 0],\u001b[39;00m\n\u001b[32m    503\u001b[39m \u001b[33;03m    ...                    [0, 1, 1]])\u001b[39;00m\n\u001b[32m    504\u001b[39m \u001b[33;03m    >>> multilabel_confusion_matrix(y_true, y_pred)\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[33;03m    array([[[1, 0],\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[33;03m            [0, 1]],\u001b[39;00m\n\u001b[32m    507\u001b[39m \u001b[33;03m    <BLANKLINE>\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[33;03m           [[1, 0],\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[33;03m            [0, 1]],\u001b[39;00m\n\u001b[32m    510\u001b[39m \u001b[33;03m    <BLANKLINE>\u001b[39;00m\n\u001b[32m    511\u001b[39m \u001b[33;03m           [[0, 1],\u001b[39;00m\n\u001b[32m    512\u001b[39m \u001b[33;03m            [1, 0]]])\u001b[39;00m\n\u001b[32m    513\u001b[39m \n\u001b[32m    514\u001b[39m \u001b[33;03m    Multiclass case:\u001b[39;00m\n\u001b[32m    515\u001b[39m \n\u001b[32m    516\u001b[39m \u001b[33;03m    >>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\u001b[39;00m\n\u001b[32m    517\u001b[39m \u001b[33;03m    >>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\u001b[39;00m\n\u001b[32m    518\u001b[39m \u001b[33;03m    >>> multilabel_confusion_matrix(y_true, y_pred,\u001b[39;00m\n\u001b[32m    519\u001b[39m \u001b[33;03m    ...                             labels=[\"ant\", \"bird\", \"cat\"])\u001b[39;00m\n\u001b[32m    520\u001b[39m \u001b[33;03m    array([[[3, 1],\u001b[39;00m\n\u001b[32m    521\u001b[39m \u001b[33;03m            [0, 2]],\u001b[39;00m\n\u001b[32m    522\u001b[39m \u001b[33;03m    <BLANKLINE>\u001b[39;00m\n\u001b[32m    523\u001b[39m \u001b[33;03m           [[5, 0],\u001b[39;00m\n\u001b[32m    524\u001b[39m \u001b[33;03m            [1, 0]],\u001b[39;00m\n\u001b[32m    525\u001b[39m \u001b[33;03m    <BLANKLINE>\u001b[39;00m\n\u001b[32m    526\u001b[39m \u001b[33;03m           [[2, 1],\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[33;03m            [1, 2]]])\u001b[39;00m\n\u001b[32m    528\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    529\u001b[39m     y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m    530\u001b[39m     xp, _ = get_namespace(y_true, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Desktop\\code_project1\\project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:106\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type == {\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m    104\u001b[39m     y_type = {\u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) > \u001b[32m1\u001b[39m:\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mClassification metrics can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m targets\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    109\u001b[39m             type_true, type_pred\n\u001b[32m    110\u001b[39m         )\n\u001b[32m    111\u001b[39m     )\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1) 예측 결과 로드\n",
    "df = pd.read_csv(\"test4_ver1/4feat_inference.csv\")\n",
    "\n",
    "# 2) 3-클래스 분류 (Low/Mid/High)\n",
    "df['pred_class3'] = pd.Categorical(df['pred_class3'], categories=['Low','Mid','High'])\n",
    "\n",
    "# 3) (옵션) 실제 레이블이 있다면 평가\n",
    "if 'label3' in df.columns:\n",
    "    print(classification_report(df['label3'], df['pred_class3'], zero_division=0))\n",
    "\n",
    "# 4) 예측 점수 분포 살펴보기\n",
    "plt.figure()\n",
    "plt.hist(df['pred_score'], bins=20)\n",
    "plt.title(\"Predicted Score Distribution\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5) 혼동행렬 시각화\n",
    "cm = confusion_matrix(df['pred_score'], df['pred_class3'], labels=['Low','Mid','High'])\n",
    "plt.figure()\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.xticks([0,1,2], ['Low','Mid','High'])\n",
    "plt.yticks([0,1,2], ['Low','Mid','High'])\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.text(j, i, cm[i,j], ha='center', va='center', color='white')\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf14d29",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30cb18b",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c20bed",
   "metadata": {},
   "source": [
    "#----------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
