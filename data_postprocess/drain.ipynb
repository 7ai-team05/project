{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39c763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* Running on public URL: https://25e5d76dbffe845179.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://25e5d76dbffe845179.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# 1) 내 정보로 아래 두 변수를 수정하세요.\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "PREDICTION_KEY = \"BBvYKDdr5RDpSMjG34Z2XXw3hLxzlAQkktCPXwHTLleSagQPHGg0JQQJ99BEACYeBjFXJ3w3AAAIACOGH9bC\"\n",
    "ENDPOINT_URL    = \"https://7aiteam05cv-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/2ae6121f-4235-4dce-bf2a-fbace9444880/classify/iterations/Iteration12/image\"\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "\n",
    "\n",
    "def predict_clean_heavy(img: Image.Image) -> dict:\n",
    "    \"\"\"\n",
    "    Gradio로 입력받은 PIL 이미지를 JPEG 바이트로 변환해\n",
    "    Custom Vision Prediction API에 POST 요청을 보냅니다.\n",
    "    반환되는 JSON 안의 'predictions' 필드에서\n",
    "    tagName(라벨)과 probability(확률)만 뽑아서\n",
    "    {'clean': 확률, 'heavy': 확률} 형태의 dict를 리턴합니다.\n",
    "    \"\"\"\n",
    "    # 1) PIL Image → JPEG 바이트 변환\n",
    "    with io.BytesIO() as buffer:\n",
    "        img.save(buffer, format=\"JPEG\")\n",
    "        image_bytes = buffer.getvalue()\n",
    "\n",
    "    # 2) 요청 헤더 구성\n",
    "    headers = {\n",
    "        \"Prediction-Key\": PREDICTION_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "\n",
    "    # 3) API 호출 (POST)\n",
    "    response = requests.post(\n",
    "        ENDPOINT_URL,\n",
    "        headers=headers,\n",
    "        data=image_bytes\n",
    "    )\n",
    "    response.raise_for_status()  # 오류 시 예외 발생\n",
    "\n",
    "    # 4) JSON 결과 파싱\n",
    "    result = response.json()\n",
    "    predictions = result.get(\"predictions\", [])\n",
    "\n",
    "    # 5) Gradio Label 컴포넌트에 맞게 {label:probability} dict 생성\n",
    "    output = {}\n",
    "    for pred in predictions:\n",
    "        name = pred.get(\"tagName\")\n",
    "        prob = pred.get(\"probability\", 0.0)\n",
    "        # Gradio Label에 주려면 0~1 사이의 확률 값을 그대로 넘기면 됩니다.\n",
    "        output[name] = prob\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    demo = gr.Interface(\n",
    "    fn=predict_clean_heavy,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=2, label=\"확률 (clean vs heavy)\"),\n",
    "    title=\"Custom Vision: Clean vs Heavy 분류\",\n",
    "    description=\"\"\"\n",
    "    웹캠으로 빗물받이 사진을 찍으면 Azure Custom Vision 이진 분류 모델에 보내서 \n",
    "    'clean'과 'heavy' 각각의 확률을 실시간으로 보여줍니다.\n",
    "    \"\"\",\n",
    "    allow_flagging=\"never\"\n",
    "    )\n",
    "\n",
    "    demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb270b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://dd3dcc1d9ae3cdecf0.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://dd3dcc1d9ae3cdecf0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# 1) 아래 두 변수를 실제 값으로 수정하세요: (빗물받이 여부 판별 모델)\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "DETECTION_KEY = \"5sloqMYWiZSpfCd7HZgQ9ZpfuQAXnRWwjSw648WjXGr5Fy5f7imcJQQJ99BFACYeBjFXJ3w3AAAIACOGBDCR\"\n",
    "DETECTION_ENDPOINT_URL = \"https://7aiteam05ai012-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/f360eeb2-f8df-441e-8bed-f27d3ef1797a/detect/iterations/Iteration2/image\"\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# 2) 아래 두 변수를 실제 값으로 수정하세요: (오염도 분류 모델: Clean vs Heavy)\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "POLLUTION_KEY = \"BBvYKDdr5RDpSMjG34Z2XXw3hLxzlAQkktCPXwHTLleSagQPHGg0JQQJ99BEACYeBjFXJ3w3AAAIACOGH9bC\"\n",
    "POLLUTION_ENDPOINT_URL = \"https://7aiteam05cv-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/2ae6121f-4235-4dce-bf2a-fbace9444880/classify/iterations/Iteration12/image\"\n",
    "\n",
    "\n",
    "def predict_sequence(img: Image.Image) -> tuple[dict, dict, str]:\n",
    "    \"\"\"\n",
    "    1) Gradio로 입력받은 PIL 이미지를 JPEG 바이트로 변환\n",
    "    2) [빗물받이 여부 모델]에 POST 요청 -> 결과를 { 'drain':확률, 'not_drain':확률 }로 정리\n",
    "    3) 'drain' 확률이 'not_drain'보다 높으면(=빗물받이 판정):\n",
    "         -> [오염도 모델]에 POST 요청 -> 결과를 { 'clean':확률, 'heavy':확률 }로 정리\n",
    "       아니면(=빗물받이가 아니면) 두 번째 모델 호출 생략\n",
    "    4) 상태 메시지를 세 가지 경우로 분기하여 문자열로 생성\n",
    "       - 빗물받이가 아님\n",
    "       - 오염도(heavy) < 70%\n",
    "       - 오염도(heavy) ≥ 70% & < 90%\n",
    "       - 오염도(heavy) ≥ 90%\n",
    "    5) Gradio에 (detection_dict, pollution_dict, status_text) 튜플로 반환\n",
    "    \"\"\"\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    # A) PIL Image → JPEG 바이트 변환 (공통)\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    with io.BytesIO() as buffer:\n",
    "        img.save(buffer, format=\"JPEG\")\n",
    "        image_bytes = buffer.getvalue()\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    # B) 빗물받이 여부 모델 호출 (Detection)\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    headers_det = {\n",
    "        \"Prediction-Key\": DETECTION_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "    response_det = requests.post(\n",
    "        DETECTION_ENDPOINT_URL,\n",
    "        headers=headers_det,\n",
    "        data=image_bytes\n",
    "    )\n",
    "    response_det.raise_for_status()\n",
    "    result_det = response_det.json()\n",
    "    preds_det = result_det.get(\"predictions\", [])\n",
    "\n",
    "    # 출력 딕셔너리를 모두 소문자 키로 정리\n",
    "    detection_dict = {}\n",
    "    for pred in preds_det:\n",
    "        name = pred.get(\"tagName\", \"\")\n",
    "        prob = pred.get(\"probability\", 0.0)\n",
    "        detection_dict[name.lower()] = prob\n",
    "    # 예) detection_dict == { 'drain': 0.85, 'not_drain': 0.15 }\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    # C) 빗물받이 판정 기준: drain 확률 vs not_drain 확률\n",
    "    #    (여기서는 더 높은 쪽을 선택)\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    drain_prob = detection_dict.get(\"street_drain\", 0.0)\n",
    "    not_drain_prob = detection_dict.get(\"unstreet_drain\", 0.0)\n",
    "\n",
    "    # 기본값: 오염도 모델 호출을 건너뛸 때 사용\n",
    "    pollution_dict = { \"clean\": 0.0, \"heavy\": 0.0 }\n",
    "    status_text = \"\"\n",
    "\n",
    "    if drain_prob > not_drain_prob:\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        # D) 빗물받이(Drain)으로 판정되었으므로 오염도(클린/헤비) 모델 호출\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        headers_pol = {\n",
    "            \"Prediction-Key\": POLLUTION_KEY,\n",
    "            \"Content-Type\": \"application/octet-stream\"\n",
    "        }\n",
    "        response_pol = requests.post(\n",
    "            POLLUTION_ENDPOINT_URL,\n",
    "            headers=headers_pol,\n",
    "            data=image_bytes\n",
    "        )\n",
    "        response_pol.raise_for_status()\n",
    "        result_pol = response_pol.json()\n",
    "        preds_pol = result_pol.get(\"predictions\", [])\n",
    "\n",
    "        # clean/heavy 확률을 소문자 키로 정리\n",
    "        pollution_dict = {}\n",
    "        for pred in preds_pol:\n",
    "            name = pred.get(\"tagName\", \"\")\n",
    "            prob = pred.get(\"probability\", 0.0)\n",
    "            pollution_dict[name.lower()] = prob\n",
    "        # 예) pollution_dict == { 'clean': 0.10, 'heavy': 0.90 }\n",
    "\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        # E) pollution_dict['heavy'] 값에 따라 상태 메시지 분기\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        heavy_prob = pollution_dict.get(\"heavy\", 0.0)\n",
    "        if heavy_prob >= 0.9:\n",
    "            status_text = \"🚨 Heavy 수준: 확률 ≥ 90% (매우 막힘)\"\n",
    "        elif heavy_prob >= 0.7:\n",
    "            status_text = \"⚠️ Heavy 수준: 확률 ≥ 70% (중간/높음 막힘)\"\n",
    "        elif heavy_prob >= 0.6:\n",
    "            status_text = \"✅ Heavy 확률 ≥ 60% (크게 막힌 상태 아님)\"\n",
    "        else:\n",
    "            status_text = \"✅ Clean\"\n",
    "    else:\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        # F) 빗물받이가 아닐 때: pollution_dict는 0.0 기본값 사용, 메시지 설정\n",
    "        # ─────────────────────────────────────────────────────────────────\n",
    "        status_text = \"❌ 빗물받이가 아닙니다.\"\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    # G) Gradio로 반환: (빗물받이 판별 dict, 오염도 dict, 상태 메시지)\n",
    "    # ─────────────────────────────────────────────────────────────────\n",
    "    return detection_dict, pollution_dict, status_text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo = gr.Interface(\n",
    "        fn=predict_sequence,\n",
    "        inputs=gr.Image(type=\"pil\"),\n",
    "        outputs=[\n",
    "            gr.Label(label=\"빗물받이 여부 (Drain vs NotDrain)\"),\n",
    "            gr.Label(label=\"오염도 (Clean vs Heavy)\"),\n",
    "            gr.Text(label=\"상태 메시지\")\n",
    "        ],\n",
    "        title=\"Custom Vision: 빗물받이 여부 ➔ 오염도 순차 분류\",\n",
    "        description=\"\"\"\n",
    "        1. 먼저 업로드된 사진이 빗물받이인지 아닌지 Custom Vision 모델로 판정합니다.  \n",
    "        2. '빗물받이(drain)'로 판정되면, 두 번째 모델을 호출하여 'clean' vs 'heavy' 오염도를 예측합니다.  \n",
    "        3. 결과는 각각 확률과 상태 메시지로 보여줍니다.  \n",
    "        - 빗물받이가 아닌 경우: 상태 메시지에 '❌ 빗물받이가 아닙니다.' 출력  \n",
    "        - 빗물받이인 경우, heavy 확률에 따라 70%·90% 경계로 상태 메시지 분기  \n",
    "        \"\"\",\n",
    "        allow_flagging=\"never\"\n",
    "    )\n",
    "    demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ddc9e1",
   "metadata": {},
   "source": [
    "## 빗물 받이 확인 여부 + 빗물 받이 상태 + 위치 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "276eec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\interface.py:416: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://2e6616778c4756c34e.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2e6616778c4756c34e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 403, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\route_utils.py\", line 834, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 714, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 734, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 74, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\responses.py\", line 359, in __call__\n",
      "    await self._handle_simple(send, send_header_only)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\responses.py\", line 388, in _handle_simple\n",
      "    await send({\"type\": \"http.response.body\", \"body\": chunk, \"more_body\": more_body})\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 39, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 39, in sender\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 162, in _send\n",
      "    await send(message)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 507, in send\n",
      "    output = self.conn.send(event=h11.EndOfMessage())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h11\\_connection.py\", line 538, in send\n",
      "    data_list = self.send_with_data_passthrough(event)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h11\\_connection.py\", line 571, in send_with_data_passthrough\n",
      "    writer(event, data_list.append)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h11\\_writers.py\", line 67, in __call__\n",
      "    self.send_eom(event.headers, write)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h11\\_writers.py\", line 96, in send_eom\n",
      "    raise LocalProtocolError(\"Too little data for declared Content-Length\")\n",
      "h11._util.LocalProtocolError: Too little data for declared Content-Length\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "from PIL import Image, ExifTags\n",
    "import gradio as gr\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# 1) 빗물받이 여부 판별 모델 API 정보\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "DETECTION_KEY = \"5sloqMYWiZSpfCd7HZgQ9ZpfuQAXnRWwjSw648WjXGr5Fy5f7imcJQQJ99BFACYeBjFXJ3w3AAAIACOGBDCR\"\n",
    "DETECTION_ENDPOINT_URL = \"https://7aiteam05ai012-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/f360eeb2-f8df-441e-8bed-f27d3ef1797a/detect/iterations/Iteration2/image\"\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# 2) 오염도 분류 모델 API 정보\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "POLLUTION_KEY = \"BBvYKDdr5RDpSMjG34Z2XXw3hLxzlAQkktCPXwHTLleSagQPHGg0JQQJ99BEACYeBjFXJ3w3AAAIACOGH9bC\"\n",
    "POLLUTION_ENDPOINT_URL = \"https://7aiteam05cv-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/2ae6121f-4235-4dce-bf2a-fbace9444880/classify/iterations/Iteration12/image\"\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# GPS 추출 함수들\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "def get_decimal_from_dms(dms, ref):\n",
    "    deg = float(dms[0])\n",
    "    minu = float(dms[1])\n",
    "    sec = float(dms[2])\n",
    "    dec = deg + (minu / 60.0) + (sec / 3600.0)\n",
    "    if ref in ('S', 'W'):\n",
    "        dec = -dec\n",
    "    return dec\n",
    "\n",
    "def extract_gps(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    exif = img._getexif()\n",
    "    if not exif:\n",
    "        return None\n",
    "\n",
    "    gps_info = {}\n",
    "    for tag_id, value in exif.items():\n",
    "        tag = ExifTags.TAGS.get(tag_id)\n",
    "        if tag == 'GPSInfo':\n",
    "            for key, val in value.items():\n",
    "                subtag = ExifTags.GPSTAGS.get(key)\n",
    "                gps_info[subtag] = val\n",
    "\n",
    "    required = ('GPSLatitudeRef', 'GPSLatitude', 'GPSLongitudeRef', 'GPSLongitude')\n",
    "    if not all(k in gps_info for k in required):\n",
    "        return None\n",
    "\n",
    "    lat = get_decimal_from_dms(gps_info['GPSLatitude'], gps_info['GPSLatitudeRef'])\n",
    "    lon = get_decimal_from_dms(gps_info['GPSLongitude'], gps_info['GPSLongitudeRef'])\n",
    "    return (lat, lon)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# 메인 예측 함수 (파일 경로 기반)\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "def predict_sequence(image_path: str):\n",
    "    try:\n",
    "        # PIL 이미지 열기\n",
    "        pil_img = Image.open(image_path)\n",
    "\n",
    "        # A) 이미지 바이트 변환\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            image_bytes = f.read()\n",
    "\n",
    "        # B) 빗물받이 여부 예측\n",
    "        headers_det = {\n",
    "            \"Prediction-Key\": DETECTION_KEY,\n",
    "            \"Content-Type\": \"application/octet-stream\"\n",
    "        }\n",
    "        response_det = requests.post(DETECTION_ENDPOINT_URL, headers=headers_det, data=image_bytes)\n",
    "        response_det.raise_for_status()\n",
    "        preds_det = response_det.json().get(\"predictions\", [])\n",
    "        detection_dict = {pred[\"tagName\"].lower(): pred[\"probability\"] for pred in preds_det}\n",
    "\n",
    "        drain_prob = detection_dict.get(\"street_drain\", 0.0)\n",
    "        not_drain_prob = detection_dict.get(\"unstreet_drain\", 0.0)\n",
    "\n",
    "        pollution_dict = {\"clean\": 0.0, \"heavy\": 0.0}\n",
    "        status_text = \"\"\n",
    "\n",
    "        # C) 오염도 분류 (빗물받이일 경우만)\n",
    "        if drain_prob > not_drain_prob:\n",
    "            headers_pol = {\n",
    "                \"Prediction-Key\": POLLUTION_KEY,\n",
    "                \"Content-Type\": \"application/octet-stream\"\n",
    "            }\n",
    "            response_pol = requests.post(POLLUTION_ENDPOINT_URL, headers=headers_pol, data=image_bytes)\n",
    "            response_pol.raise_for_status()\n",
    "            preds_pol = response_pol.json().get(\"predictions\", [])\n",
    "            pollution_dict = {pred[\"tagName\"].lower(): pred[\"probability\"] for pred in preds_pol}\n",
    "\n",
    "            heavy_prob = pollution_dict.get(\"heavy\", 0.0)\n",
    "            if heavy_prob >= 0.9:\n",
    "                status_text = \"🚨 Heavy 수준: 확률 ≥ 90% (매우 막힘)\"\n",
    "            elif heavy_prob >= 0.7:\n",
    "                status_text = \"⚠️ Heavy 수준: 확률 ≥ 70% (중간/높음 막힘)\"\n",
    "            elif heavy_prob >= 0.6:\n",
    "                status_text = \"✅ Heavy 확률 ≥ 60% (크게 막힌 상태 아님)\"\n",
    "            else:\n",
    "                status_text = \"✅ Clean\"\n",
    "        else:\n",
    "            status_text = \"❌ 빗물받이가 아닙니다.\"\n",
    "\n",
    "        # D) GPS 추출\n",
    "        try:\n",
    "            coords = extract_gps(image_path)\n",
    "            if coords:\n",
    "                lat_lon_text = f\"📍 위도: {coords[0]:.6f}, 경도: {coords[1]:.6f}\"\n",
    "            else:\n",
    "                lat_lon_text = \"📍 위치 정보 없음\"\n",
    "        except Exception as gps_err:\n",
    "            lat_lon_text = f\"📍 위치 정보 추출 실패: {gps_err}\"\n",
    "\n",
    "        return detection_dict, pollution_dict, status_text, lat_lon_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": 1}, {\"error\": 1}, f\"❌ 예외 발생: {str(e)}\", \"❌ 위치 정보 추출 실패\"\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# Gradio 인터페이스\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    demo = gr.Interface(\n",
    "        fn=predict_sequence,\n",
    "        inputs=gr.Image(type=\"filepath\"),\n",
    "        outputs=[\n",
    "            gr.Label(label=\"빗물받이 여부 (Drain vs NotDrain)\"),\n",
    "            gr.Label(label=\"오염도 (Clean vs Heavy)\"),\n",
    "            gr.Text(label=\"상태 메시지\"),\n",
    "            gr.Text(label=\"GPS 위치 정보\")\n",
    "        ],\n",
    "        title=\"Custom Vision: 빗물받이 여부 ➔ 오염도 ➔ 위치 정보\",\n",
    "        description=\"\"\"\n",
    "1. 업로드된 사진이 빗물받이인지 판단  \n",
    "2. 빗물받이라면 오염도(Clean vs Heavy)를 예측  \n",
    "3. JPEG의 EXIF 위치 정보가 있으면 위도/경도 출력  \n",
    "\"\"\",\n",
    "        allow_flagging=\"never\"\n",
    "    )\n",
    "    demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
